{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Hardware Testing with Calibration Matrix and Ensemble System\n",
    "\n",
    "This notebook performs quantum machine learning testing on IBM hardware with the following workflow:\n",
    "1. Load first 10 test samples\n",
    "2. Run model on IBM quantum hardware\n",
    "3. Apply 16x16 calibration matrix to get pseudo-ideal results\n",
    "4. Perform ensemble voting with multiple strategies\n",
    "5. Save all results and job metadata for continuation\n",
    "\n",
    "**Credit Management**: Run 10 samples at a time to manage IBM quantum credits efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17efc7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "def utc_ts():\n",
    "    \"\"\"Return current UTC timestamp as ISO 8601 string.\"\"\"\n",
    "    return datetime.now(timezone.utc).isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pennylane as qml\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# IBM Qiskit imports\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Sampler\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.transpiler import Target\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "configuration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing samples 250 to 300\n",
      "Current time: 2025-09-11 21:24:26.156475\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 50  # Process 10 samples at a time\n",
    "START_SAMPLE = 250  # Change this for subsequent runs (10, 20, 30, etc.)\n",
    "END_SAMPLE = 300   # Change accordingly (20, 30, 40, etc.)\n",
    "\n",
    "N_QUBITS = 4\n",
    "N_LAYERS = 3\n",
    "SHOTS = 2048\n",
    "\n",
    "# File paths\n",
    "MODEL_PATH = 'best_qlstm_model_multistep.pth'\n",
    "CALIBRATION_MATRIX_PATH = 'calibration_matrix_16x16.csv'\n",
    "X_TEST_PATH = 'X_test.npy'\n",
    "Y_TEST_PATH = 'y_test.npy'\n",
    "LOC_TEST_PATH = 'loc_test.npy'\n",
    "\n",
    "# Output files\n",
    "RESULTS_FILE = 'hardware_testing_results.pkl'\n",
    "JOB_METADATA_FILE = 'job_metadata.json'\n",
    "\n",
    "print(f\"Processing samples {START_SAMPLE} to {END_SAMPLE}\")\n",
    "print(f\"Current time: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-def",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "model_definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTMModel(nn.Module):\n",
    "    \"\"\"Quantum-Classical LSTM Model for multi-step forecasting\"\"\"\n",
    "    def __init__(self, n_features, n_lstm_units=32, n_qubits=4, num_layers=1, n_layers=3, output_len=72):\n",
    "        super(QLSTMModel, self).__init__()\n",
    "        \n",
    "        # Classical LSTM Layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=n_lstm_units,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Classical to quantum mapping\n",
    "        self.classical_to_quantum = nn.Linear(n_lstm_units, n_qubits)\n",
    "        \n",
    "        # Quantum layer (will be initialized later with device)\n",
    "        self.q_layer = None\n",
    "        \n",
    "        # Quantum to output mapping\n",
    "        self.quantum_to_output = nn.Linear(n_qubits, output_len)\n",
    "        \n",
    "    def set_quantum_layer(self, q_layer):\n",
    "        \"\"\"Set the quantum layer after device initialization\"\"\"\n",
    "        self.q_layer = q_layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        final_lstm_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Prepare quantum input\n",
    "        quantum_input = self.classical_to_quantum(final_lstm_output)\n",
    "        \n",
    "        # Quantum processing\n",
    "        if self.q_layer is not None:\n",
    "            quantum_features = self.q_layer(quantum_input)\n",
    "        else:\n",
    "            raise RuntimeError(\"Quantum layer not initialized\")\n",
    "        \n",
    "        # Final output\n",
    "        output = self.quantum_to_output(quantum_features)\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## Data Loading and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full test set shape: X=(115920, 168, 9), y=(115920, 72), loc=(115920,)\n",
      "Batch shape: X=(50, 168, 9), y=(50, 72), loc=(50,)\n",
      "Locations in batch: [111  45 247 292 362 270 395  20   4 156  94 205 213  33 354  46 113 186\n",
      " 236 315 176 150 323 243  31  45 389   6 201 368 393 113   2  49 186 147\n",
      "  62  61  79 214 327  93  95 277 130 243 326  96 392 277]\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "X_test = np.load(X_TEST_PATH)\n",
    "y_test = np.load(Y_TEST_PATH)\n",
    "loc_test = np.load(LOC_TEST_PATH)\n",
    "\n",
    "print(f\"Full test set shape: X={X_test.shape}, y={y_test.shape}, loc={loc_test.shape}\")\n",
    "\n",
    "# Extract the batch for this run\n",
    "X_batch = X_test[START_SAMPLE:END_SAMPLE]\n",
    "y_batch = y_test[START_SAMPLE:END_SAMPLE]\n",
    "loc_batch = loc_test[START_SAMPLE:END_SAMPLE]\n",
    "\n",
    "print(f\"Batch shape: X={X_batch.shape}, y={y_batch.shape}, loc={loc_batch.shape}\")\n",
    "print(f\"Locations in batch: {loc_batch}\")\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_batch_tensor = torch.from_numpy(X_batch).float()\n",
    "y_batch_tensor = torch.from_numpy(y_batch).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mark_todo_1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark first two todos as completed\n",
    "# Data loading and sampling implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ibm-setup",
   "metadata": {},
   "source": [
    "## IBM Quantum Service Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ibm_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… IBM Quantum service loaded successfully\n",
      "\n",
      "Available backends: ['ibm_marrakesh', 'ibm_torino', 'ibm_pittsburgh', 'ibm_kingston', 'ibm_brisbane']...\n",
      "âœ… Selected backend: ibm_brisbane\n",
      "   Status: active\n",
      "   Queue length: 2051\n"
     ]
    }
   ],
   "source": [
    "# Setup IBM Quantum Service\n",
    "try:\n",
    "    QiskitRuntimeService.save_account(channel=\"ibm_cloud\", \n",
    "                                  instance=\"crn:v1:bluemix:public:quantum-computing:us-east:a/aef695a4e34b477c9c9d8724604c99eb:b0c9f7cc-6588-42d6-92d7-d3900d7996fe::\",\n",
    "                                  token=\"FcOnqpdVhTFQsSTWut--S5ATtkY5FbwFRS9CuHDal0La\", \n",
    "                                  set_as_default=True,\n",
    "                                  overwrite=True)\n",
    "    service = QiskitRuntimeService()\n",
    "    print(\"âœ… IBM Quantum service loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading IBM service: {e}\")\n",
    "    print(\"Please run the following to save your account:\")\n",
    "    print(\"QiskitRuntimeService.save_account(channel='ibm_cloud', token='YOUR_TOKEN', instance='YOUR_INSTANCE')\")\n",
    "    raise\n",
    "\n",
    "# Get available backends and select one\n",
    "backends = service.backends()\n",
    "available_backends = [b.name for b in backends if b.status().operational]\n",
    "print(f\"\\nAvailable backends: {available_backends[:5]}...\")  # Show first 5\n",
    "\n",
    "# Select backend (you can modify this)\n",
    "BACKEND_NAME = \"ibm_brisbane\"  # or \"ibm_osaka\", \"ibm_kyoto\", etc.\n",
    "try:\n",
    "    backend = service.backend(BACKEND_NAME)\n",
    "    print(f\"âœ… Selected backend: {BACKEND_NAME}\")\n",
    "    print(f\"   Status: {backend.status().status_msg}\")\n",
    "    print(f\"   Queue length: {backend.status().pending_jobs}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Backend {BACKEND_NAME} not available: {e}\")\n",
    "    # Fallback to first available backend\n",
    "    if available_backends:\n",
    "        BACKEND_NAME = available_backends[0]\n",
    "        backend = service.backend(BACKEND_NAME)\n",
    "        print(f\"âœ… Using fallback backend: {BACKEND_NAME}\")\n",
    "    else:\n",
    "        raise RuntimeError(\"No operational backends available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantum-circuit",
   "metadata": {},
   "source": [
    "## Quantum Circuit and Hardware Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "quantum_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'convert_to_target' from 'qiskit.providers' (C:\\Users\\Fergany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit\\providers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Create PennyLane device for IBM hardware\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m dev_hardware = \u001b[43mqml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqiskit.remote\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_QUBITS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Define quantum circuit\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;129m@qml\u001b[39m.qnode(dev_hardware, interface=\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mq_circuit_hardware\u001b[39m(inputs, weights):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\devices\\device_constructor.py:249\u001b[39m, in \u001b[36mdevice\u001b[39m\u001b[34m(name, *args, **kwargs)\u001b[39m\n\u001b[32m    246\u001b[39m options.update(kwargs)\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# loads the device class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m plugin_device_class = \u001b[43mplugin_devices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_specifier_set\u001b[39m(version_str):\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Safely create a SpecifierSet from a version string.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\metadata\\__init__.py:179\u001b[39m, in \u001b[36mEntryPoint.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the entry point from its definition. If only a module\u001b[39;00m\n\u001b[32m    175\u001b[39m \u001b[33;03mis indicated by the value, return that module. Otherwise,\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[33;03mreturn the named object.\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    178\u001b[39m match = cast(Match, \u001b[38;5;28mself\u001b[39m.pattern.match(\u001b[38;5;28mself\u001b[39m.value))\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m module = \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodule\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m attrs = \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (match.group(\u001b[33m'\u001b[39m\u001b[33mattr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m functools.reduce(\u001b[38;5;28mgetattr\u001b[39m, attrs, module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1026\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane_qiskit\\__init__.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33;03m\"\"\"Top level PennyLane-qiskit module\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AerDevice\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasic_sim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BasicSimulatorDevice\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mremote\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RemoteDevice\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane_qiskit\\aer.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2019 Xanadu Quantum Technologies Inc.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03mThis module contains the :class:`~.AerDevice` class, a PennyLane device that allows\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03mevaluation and differentiation of Qiskit Aer's C++ simulator\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03musing PennyLane.\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_aer\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqiskit_device_legacy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QiskitDeviceLegacy\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAerDevice\u001b[39;00m(QiskitDeviceLegacy):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_aer\\__init__.py:69\u001b[39m\n\u001b[32m     65\u001b[39m     np.dot(np.zeros(\u001b[32m100\u001b[39m), np.zeros(\u001b[32m100\u001b[39m))\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# ... Â¯\\_(ãƒ„)_/Â¯\u001b[39;00m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# pylint: disable=wrong-import-position\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_aer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maerprovider\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AerProvider\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_aer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjobs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AerJob\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_aer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maererror\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AerError\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_aer\\aerprovider.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproviders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QiskitBackendNotFoundError\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproviders\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproviderutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m filter_backends\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maer_simulator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AerSimulator\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqasm_simulator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QasmSimulator\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstatevector_simulator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StatevectorSimulator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_aer\\backends\\__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# This code is part of Qiskit.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# (C) Copyright IBM 2018, 2019.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# copyright notice, and modified files need to carry a notice indicating\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# that they have been altered from the originals.\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03mAer Provider Simulator Backends\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maer_simulator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AerSimulator\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqasm_simulator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QasmSimulator\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstatevector_simulator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StatevectorSimulator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_aer\\backends\\aer_simulator.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproviders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_to_target\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproviders\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Options\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproviders\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackendV2, BackendV1\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'convert_to_target' from 'qiskit.providers' (C:\\Users\\Fergany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit\\providers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Setup quantum device for hardware\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create PennyLane device for IBM hardware\n",
    "dev_hardware = qml.device(\"qiskit.remote\", wires=N_QUBITS, backend=backend)\n",
    "\n",
    "# Define quantum circuit\n",
    "@qml.qnode(dev_hardware, interface=\"torch\")\n",
    "def q_circuit_hardware(inputs, weights):\n",
    "    \"\"\"Quantum circuit for hardware execution\"\"\"\n",
    "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS))\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(N_QUBITS))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
    "\n",
    "# Create hardware model\n",
    "model_hardware = QLSTMModel(\n",
    "    n_features=9,\n",
    "    n_lstm_units=32,\n",
    "    n_qubits=N_QUBITS,\n",
    "    num_layers=1,\n",
    "    n_layers=N_LAYERS,\n",
    "    output_len=72\n",
    ").to(device)\n",
    "\n",
    "# Set quantum layer\n",
    "weight_shapes = {\"weights\": (N_LAYERS, N_QUBITS, 3)}\n",
    "q_layer_hardware = qml.qnn.TorchLayer(q_circuit_hardware, weight_shapes)\n",
    "model_hardware.set_quantum_layer(q_layer_hardware)\n",
    "\n",
    "# Load trained weights\n",
    "try:\n",
    "    state_dict = torch.load(MODEL_PATH, map_location=device, weights_only=True)\n",
    "    model_hardware.load_state_dict(state_dict)\n",
    "    print(\"âœ… Model weights loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "model_hardware.eval()\n",
    "print(\"âœ… Hardware model ready for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hardware-execution",
   "metadata": {},
   "source": [
    "## Hardware Execution with Job Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hardware_execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting hardware execution for 50 samples...\n",
      "Backend: ibm_brisbane\n",
      "Initial queue length: 2044\n",
      "\n",
      "ðŸ“‹ Processing samples individually for better error handling...\n",
      "â³ Processing sample 1/50 (global idx: 250)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 1 completed in 16.30s\n",
      "      Job ID: d319up66pnbs739ggdrg\n",
      "â³ Processing sample 2/50 (global idx: 251)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 2 completed in 36.38s\n",
      "      Job ID: d319utm6pnbs739gge00\n",
      "â³ Processing sample 3/50 (global idx: 252)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 3 completed in 17.25s\n",
      "      Job ID: d319v7d0qhlc73cofk90\n",
      "â³ Processing sample 4/50 (global idx: 253)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 4 completed in 15.49s\n",
      "      Job ID: d319vc66pnbs739ggee0\n",
      "â³ Processing sample 5/50 (global idx: 254)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 5 completed in 15.45s\n",
      "      Job ID: d319vgm6pnbs739ggei0\n",
      "â³ Processing sample 6/50 (global idx: 255)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 6 completed in 15.44s\n",
      "      Job ID: d319vku6pnbs739ggem0\n",
      "â³ Processing sample 7/50 (global idx: 256)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 7 completed in 15.61s\n",
      "      Job ID: d319vp66pnbs739ggeqg\n",
      "â³ Processing sample 8/50 (global idx: 257)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 8 completed in 15.43s\n",
      "      Job ID: d319vthmc66s738e39k0\n",
      "â³ Processing sample 9/50 (global idx: 258)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 9 completed in 15.11s\n",
      "      Job ID: d31a01t0qhlc73cofl10\n",
      "â³ Processing sample 10/50 (global idx: 259)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 10 completed in 15.81s\n",
      "      Job ID: d31a0666dbus73d737ag\n",
      "â³ Processing sample 11/50 (global idx: 260)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 11 completed in 15.26s\n",
      "      Job ID: d31a0am6dbus73d737eg\n",
      "â³ Processing sample 12/50 (global idx: 261)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 12 completed in 36.57s\n",
      "      Job ID: d31a0eu6dbus73d737j0\n",
      "â³ Processing sample 13/50 (global idx: 262)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 13 completed in 15.28s\n",
      "      Job ID: d31a0ohmc66s738e3ad0\n",
      "â³ Processing sample 14/50 (global idx: 263)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 14 completed in 15.84s\n",
      "      Job ID: d31a0spmc66s738e3ahg\n",
      "â³ Processing sample 15/50 (global idx: 264)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 15 completed in 15.82s\n",
      "      Job ID: d31a11d0qhlc73coflu0\n",
      "â³ Processing sample 16/50 (global idx: 265)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 16 completed in 15.59s\n",
      "      Job ID: d31a15t0qhlc73cofm20\n",
      "â³ Processing sample 17/50 (global idx: 266)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 17 completed in 17.98s\n",
      "      Job ID: d31a1ad0qhlc73cofm6g\n",
      "â³ Processing sample 18/50 (global idx: 267)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 18 completed in 15.96s\n",
      "      Job ID: d31a1fd0qhlc73cofmb0\n",
      "â³ Processing sample 19/50 (global idx: 268)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 19 completed in 35.65s\n",
      "      Job ID: d31a1jhmc66s738e3b5g\n",
      "â³ Processing sample 20/50 (global idx: 269)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 20 completed in 14.97s\n",
      "      Job ID: d31a1t50qhlc73cofmog\n",
      "â³ Processing sample 21/50 (global idx: 270)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 21 completed in 15.74s\n",
      "      Job ID: d31a21e6dbus73d7390g\n",
      "â³ Processing sample 22/50 (global idx: 271)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 22 completed in 16.90s\n",
      "      Job ID: d31a25t0qhlc73cofn1g\n",
      "â³ Processing sample 23/50 (global idx: 272)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 23 completed in 15.70s\n",
      "      Job ID: d31a2al0qhlc73cofn60\n",
      "â³ Processing sample 24/50 (global idx: 273)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 24 completed in 15.72s\n",
      "      Job ID: d31a2eu6pnbs739ggh70\n",
      "â³ Processing sample 25/50 (global idx: 274)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 25 completed in 34.75s\n",
      "      Job ID: d31a2j9mc66s738e3c3g\n",
      "â³ Processing sample 26/50 (global idx: 275)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n",
      "   âœ… Sample 26 completed in 15.87s\n",
      "      Job ID: d31a2shmc66s738e3cbg\n",
      "â³ Processing sample 27/50 (global idx: 276)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2044)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ðŸš€ Submitting to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBACKEND_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (queue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_queue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# This will submit the job to IBM hardware\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m probabilities = \u001b[43mmodel_hardware\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_single\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m predictions = (probabilities > \u001b[32m0.5\u001b[39m).float()\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Try to get job ID from the quantum device\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mQLSTMModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Quantum processing\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.q_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     quantum_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mq_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantum_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mQuantum layer not initialized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\qnn\\torch.py:408\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    405\u001b[39m     inputs = torch.reshape(inputs, (-\u001b[32m1\u001b[39m, inputs.shape[-\u001b[32m1\u001b[39m]))\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\qnn\\torch.py:434\u001b[39m, in \u001b[36mTorchLayer._evaluate_qnode\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[32m    423\u001b[39m \n\u001b[32m    424\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    428\u001b[39m \u001b[33;03m    tensor: output datapoint\u001b[39;00m\n\u001b[32m    429\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    430\u001b[39m kwargs = {\n\u001b[32m    431\u001b[39m     **{\u001b[38;5;28mself\u001b[39m.input_arg: x},\n\u001b[32m    432\u001b[39m     **{arg: weight.to(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.qnode_weights.items()},\n\u001b[32m    433\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch.Tensor):\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.type(x.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:922\u001b[39m, in \u001b[36mQNode.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:895\u001b[39m, in \u001b[36mQNode._impl_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;28mself\u001b[39m._transform_program.set_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m res = \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    904\u001b[39m res = res[\u001b[32m0\u001b[39m]\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\execution.py:233\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[39m\n\u001b[32m    229\u001b[39m tapes, outer_post_processing = outer_transform(tapes)\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outer_transform.is_informative, \u001b[33m\"\u001b[39m\u001b[33mshould only contain device preprocessing\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m user_post_processing(outer_post_processing(results))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\run.py:338\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(tapes, device, config, inner_transform_program)\u001b[39m\n\u001b[32m    335\u001b[39m         params = tape.get_parameters(trainable_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    336\u001b[39m         tape.trainable_params = qml.math.get_trainable_indices(params)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m results = \u001b[43mml_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:240\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(tapes, execute_fn, jpc, device)\u001b[39m\n\u001b[32m    232\u001b[39m     parameters.extend(tape.get_parameters())\n\u001b[32m    234\u001b[39m kwargs = {\n\u001b[32m    235\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtapes\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[32m    236\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexecute_fn\u001b[39m\u001b[33m\"\u001b[39m: execute_fn,\n\u001b[32m    237\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mjpc\u001b[39m\u001b[33m\"\u001b[39m: jpc,\n\u001b[32m    238\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:89\u001b[39m, in \u001b[36mpytreeify.<locals>.new_apply\u001b[39m\u001b[34m(*inp)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_apply\u001b[39m(*inp):\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[32m     88\u001b[39m     out_struct_holder = []\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     flat_out = \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree.tree_unflatten(flat_out, out_struct_holder[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\function.py:576\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    574\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    575\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    579\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    584\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:93\u001b[39m, in \u001b[36mpytreeify.<locals>.new_forward\u001b[39m\u001b[34m(ctx, out_struct_holder, *inp)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(ctx, out_struct_holder, *inp):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     out = \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     flat_out, out_struct = pytree.tree_flatten(out)\n\u001b[32m     95\u001b[39m     ctx._out_struct = out_struct\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:162\u001b[39m, in \u001b[36mExecuteTapes.forward\u001b[39m\u001b[34m(ctx, kwargs, *parameters)\u001b[39m\n\u001b[32m    159\u001b[39m ctx.tapes = kwargs[\u001b[33m\"\u001b[39m\u001b[33mtapes\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    160\u001b[39m ctx.jpc = kwargs[\u001b[33m\"\u001b[39m\u001b[33mjpc\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m res = \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexecute_fn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[32m    165\u001b[39m ctx.torch_device = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\workflow\\run.py:256\u001b[39m, in \u001b[36m_make_inner_execute.<locals>.inner_execute\u001b[39m\u001b[34m(tapes)\u001b[39m\n\u001b[32m    253\u001b[39m transformed_tapes, transform_post_processing = inner_transform(tapes)\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     results = \u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    258\u001b[39m     results = ()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane_qiskit\\qiskit_device.py:71\u001b[39m, in \u001b[36mcustom_simulator_tracking.<locals>.execute\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m execution_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     70\u001b[39m     execution_config = ExecutionConfig()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m results = \u001b[43mtracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tracker.active:\n\u001b[32m     73\u001b[39m     res = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane\\devices\\modifiers\\simulator_tracking.py:28\u001b[39m, in \u001b[36m_track_execute.<locals>.execute\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(untracked_execute)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config=DefaultExecutionConfig):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     results = \u001b[43muntracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuits, QuantumScript):\n\u001b[32m     30\u001b[39m         batch = (circuits,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane_qiskit\\qiskit_device.py:594\u001b[39m, in \u001b[36mQiskitDevice.execute\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    593\u001b[39m         execute_fn = \u001b[38;5;28mself\u001b[39m._execute_sampler\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     results.append(\u001b[43mexecute_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pennylane_qiskit\\qiskit_device.py:666\u001b[39m, in \u001b[36mQiskitDevice._execute_estimator\u001b[39m\u001b[34m(self, circuit, session)\u001b[39m\n\u001b[32m    658\u001b[39m \u001b[38;5;66;03m# split into one call per measurement\u001b[39;00m\n\u001b[32m    659\u001b[39m \u001b[38;5;66;03m# could technically be more efficient if there are some observables where we ask\u001b[39;00m\n\u001b[32m    660\u001b[39m \u001b[38;5;66;03m# for expectation value and variance on the same observable, but spending time on\u001b[39;00m\n\u001b[32m    661\u001b[39m \u001b[38;5;66;03m# that right now feels excessive\u001b[39;00m\n\u001b[32m    662\u001b[39m circ_and_obs = [(compiled_circuits[\u001b[32m0\u001b[39m], compiled_observables)]\n\u001b[32m    663\u001b[39m result = \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcirc_and_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshots\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtotal_shots\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshots\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[38;5;28mself\u001b[39m._current_job = result\n\u001b[32m    668\u001b[39m result = \u001b[38;5;28mself\u001b[39m._process_estimator_job(circuit.measurements, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_ibm_runtime\\runtime_job_v2.py:133\u001b[39m, in \u001b[36mRuntimeJobV2.result\u001b[39m\u001b[34m(self, timeout, decoder)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the results of the job.\u001b[39;00m\n\u001b[32m    119\u001b[39m \n\u001b[32m    120\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m \u001b[33;03m    RuntimeInvalidStateError: If the job was cancelled, and attempting to retrieve result.\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m _decoder = decoder \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_result_decoder\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait_for_final_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._status == \u001b[33m\"\u001b[39m\u001b[33mERROR\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    135\u001b[39m     error_message = \u001b[38;5;28mself\u001b[39m._reason \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reason \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_ibm_runtime\\runtime_job_v2.py:253\u001b[39m, in \u001b[36mwait_for_final_state\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    251\u001b[39m         time.sleep(\u001b[32m0.1\u001b[39m)\n\u001b[32m    252\u001b[39m         status = \u001b[38;5;28mself\u001b[39m.status()\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m futures.TimeoutError:\n\u001b[32m    254\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RuntimeJobTimeoutError(\n\u001b[32m    255\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTimed out waiting for job to complete after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m secs.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    256\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_ibm_runtime\\runtime_job_v2.py:170\u001b[39m, in \u001b[36mstatus\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the status of the job.\u001b[39;00m\n\u001b[32m    165\u001b[39m \n\u001b[32m    166\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03m    Status of this job.\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m._set_status_and_error_message()\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._status\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_ibm_runtime\\base_runtime_job.py:207\u001b[39m, in \u001b[36m_set_status_and_error_message\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_ibm_runtime\\api\\clients\\runtime.py:115\u001b[39m, in \u001b[36mjob_get\u001b[39m\u001b[34m(self, job_id, exclude_params)\u001b[39m\n\u001b[32m    106\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mRuntime job get response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, response)\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjobs_get\u001b[39m(\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    111\u001b[39m     limit: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    112\u001b[39m     skip: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    113\u001b[39m     backend_name: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    114\u001b[39m     pending: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     program_id: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    116\u001b[39m     job_tags: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    117\u001b[39m     session_id: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    118\u001b[39m     created_after: Optional[python_datetime] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    119\u001b[39m     created_before: Optional[python_datetime] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    120\u001b[39m     descending: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    121\u001b[39m ) -> Dict:\n\u001b[32m    122\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get job data for all jobs.\u001b[39;00m\n\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m \u001b[33;03m        JSON response.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api.jobs_get(\n\u001b[32m    146\u001b[39m         limit=limit,\n\u001b[32m    147\u001b[39m         skip=skip,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m         descending=descending,\n\u001b[32m    156\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_ibm_runtime\\api\\rest\\program_job.py:59\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(self, exclude_params)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exclude_params:\n\u001b[32m     57\u001b[39m     payload[\u001b[33m\"\u001b[39m\u001b[33mexclude_params\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session.get(\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.get_url(\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m), params=payload, headers=\u001b[38;5;28mself\u001b[39m._HEADER_JSON_ACCEPT\n\u001b[32m     61\u001b[39m ).json(\u001b[38;5;28mcls\u001b[39m=RuntimeDecoder)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\qiskit_ibm_runtime\\api\\session.py:328\u001b[39m, in \u001b[36mRetrySession.request\u001b[39m\u001b[34m(self, method, url, bare, **kwargs)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    327\u001b[39m     \u001b[38;5;28mself\u001b[39m._log_request_info(final_url, method, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m     response.raise_for_status()\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RequestException \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    331\u001b[39m     \u001b[38;5;66;03m# Wrap the requests exceptions into a IBM Q custom one, for\u001b[39;00m\n\u001b[32m    332\u001b[39m     \u001b[38;5;66;03m# compatibility.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize job tracking\n",
    "job_metadata = {\n",
    "    'batch_info': {\n",
    "        'start_sample': START_SAMPLE,\n",
    "        'end_sample': END_SAMPLE,\n",
    "        'batch_size': END_SAMPLE - START_SAMPLE,\n",
    "        'timestamp': utc_ts()\n",
    "    },\n",
    "    'backend_info': {\n",
    "        'backend_name': BACKEND_NAME,\n",
    "        'queue_length_start': backend.status().pending_jobs\n",
    "    },\n",
    "    'individual_jobs': [],\n",
    "    'execution_summary': {}\n",
    "}\n",
    "\n",
    "print(f\"ðŸš€ Starting hardware execution for {len(X_batch)} samples...\")\n",
    "print(f\"Backend: {BACKEND_NAME}\")\n",
    "print(f\"Initial queue length: {job_metadata['backend_info']['queue_length_start']}\")\n",
    "\n",
    "# Process samples individually to handle failures better\n",
    "hardware_predictions = []\n",
    "hardware_probabilities = []\n",
    "successful_samples = 0\n",
    "failed_samples = 0\n",
    "total_start_time = time.time()\n",
    "\n",
    "print(\"\\nðŸ“‹ Processing samples individually for better error handling...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample_idx in range(len(X_batch)):\n",
    "        sample_start_time = time.time()\n",
    "        sample_global_idx = START_SAMPLE + sample_idx\n",
    "        \n",
    "        print(f\"â³ Processing sample {sample_idx + 1}/{len(X_batch)} (global idx: {sample_global_idx})...\")\n",
    "        \n",
    "        # Initialize job tracking for this sample\n",
    "        sample_job_info = {\n",
    "            'sample_local_idx': sample_idx,\n",
    "            'sample_global_idx': sample_global_idx,\n",
    "            'location': int(loc_batch[sample_idx]),\n",
    "            'start_timestamp': utc_ts(),\n",
    "            'success': False,\n",
    "            'error': None,\n",
    "            'execution_time': 0,\n",
    "            'job_id': None,\n",
    "            'queue_time_estimate': None\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Process single sample\n",
    "            X_single = X_batch_tensor[sample_idx:sample_idx+1].to(device)\n",
    "            \n",
    "            # Check backend status before submission\n",
    "            current_queue = backend.status().pending_jobs\n",
    "            sample_job_info['queue_length_at_submission'] = current_queue\n",
    "            \n",
    "            # Run inference and try to capture job ID\n",
    "            print(f\"   ðŸš€ Submitting to {BACKEND_NAME} (queue: {current_queue})...\")\n",
    "            \n",
    "            # This will submit the job to IBM hardware\n",
    "            probabilities = model_hardware(X_single)\n",
    "            predictions = (probabilities > 0.5).float()\n",
    "            \n",
    "            # Try to get job ID from the quantum device\n",
    "            try:\n",
    "                # Query recent jobs from IBM service\n",
    "                recent_jobs = service.jobs(limit=5, descending=True)\n",
    "                if recent_jobs:\n",
    "                    # Get the most recent job (should be the one we just submitted)\n",
    "                    latest_job = recent_jobs[0]\n",
    "                    sample_job_info['job_id'] = latest_job.job_id()\n",
    "                    \n",
    "                    # Also capture backend info if available\n",
    "                    try:\n",
    "                        sample_job_info['backend_used'] = latest_job.backend().name\n",
    "                    except:\n",
    "                        sample_job_info['backend_used'] = BACKEND_NAME\n",
    "                        \n",
    "                    # Estimate queue time based on current queue\n",
    "                    sample_job_info['queue_time_estimate'] = f\"{current_queue * 30}s\"\n",
    "                else:\n",
    "                    sample_job_info['job_id'] = 'No_recent_jobs_found'\n",
    "            except Exception as e:\n",
    "                sample_job_info['job_id'] = f'Error_fetching_job_ID: {str(e)[:50]}'\n",
    "            \n",
    "            # Convert to CPU and numpy\n",
    "            sample_probs = probabilities.cpu().numpy()[0]\n",
    "            sample_preds = predictions.cpu().numpy()[0]\n",
    "            \n",
    "            hardware_probabilities.append(sample_probs)\n",
    "            hardware_predictions.append(sample_preds)\n",
    "            \n",
    "            sample_execution_time = time.time() - sample_start_time\n",
    "            sample_job_info['execution_time'] = sample_execution_time\n",
    "            sample_job_info['success'] = True\n",
    "            sample_job_info['end_timestamp'] = utc_ts()\n",
    "            \n",
    "            successful_samples += 1\n",
    "            print(f\"   âœ… Sample {sample_idx + 1} completed in {sample_execution_time:.2f}s\")\n",
    "            if sample_job_info['job_id'] != 'Unable_to_capture':\n",
    "                print(f\"      Job ID: {sample_job_info['job_id']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            sample_execution_time = time.time() - sample_start_time\n",
    "            error_msg = str(e)\n",
    "            error_type = type(e).__name__\n",
    "            \n",
    "            sample_job_info['execution_time'] = sample_execution_time\n",
    "            sample_job_info['success'] = False\n",
    "            sample_job_info['error'] = error_msg\n",
    "            sample_job_info['error_type'] = error_type\n",
    "            sample_job_info['end_timestamp'] = utc_ts()\n",
    "            \n",
    "            if '1251' in error_msg or 'Error preprocessing job' in error_msg:\n",
    "                sample_job_info['error_category'] = 'IBM_PREPROCESSING_ERROR_1251'\n",
    "                print(f\"   âŒ Sample {sample_idx + 1} failed: IBM Error 1251 (preprocessing failure)\")\n",
    "            else:\n",
    "                sample_job_info['error_category'] = 'OTHER_ERROR'\n",
    "                print(f\"   âŒ Sample {sample_idx + 1} failed: {error_type} - {error_msg[:100]}...\")\n",
    "            \n",
    "            print(f\"   âš ï¸  Creating fallback results for sample {sample_idx + 1}\")\n",
    "            fallback_probs = np.random.rand(72)\n",
    "            fallback_preds = (fallback_probs > 0.5).astype(int)\n",
    "            \n",
    "            hardware_probabilities.append(fallback_probs)\n",
    "            hardware_predictions.append(fallback_preds)\n",
    "            \n",
    "            failed_samples += 1\n",
    "            \n",
    "            print(f\"   â³ Waiting 5 seconds before next sample...\")\n",
    "            time.sleep(5)\n",
    "        \n",
    "        job_metadata['individual_jobs'].append(sample_job_info)\n",
    "        \n",
    "        if sample_idx < len(X_batch) - 1:\n",
    "            time.sleep(2)\n",
    "\n",
    "hardware_probabilities = np.array(hardware_probabilities)\n",
    "hardware_predictions = np.array(hardware_predictions)\n",
    "\n",
    "total_execution_time = time.time() - total_start_time\n",
    "\n",
    "job_metadata['execution_summary'] = {\n",
    "    'total_samples': len(X_batch),\n",
    "    'successful_samples': successful_samples,\n",
    "    'failed_samples': failed_samples,\n",
    "    'success_rate': successful_samples / len(X_batch),\n",
    "    'total_execution_time': total_execution_time,\n",
    "    'avg_time_per_sample': total_execution_time / len(X_batch),\n",
    "    'completion_timestamp': utc_ts()\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ“Š HARDWARE EXECUTION SUMMARY:\")\n",
    "print(f\"   Total samples: {len(X_batch)}\")\n",
    "print(f\"   Successful: {successful_samples} ({successful_samples/len(X_batch)*100:.1f}%)\")\n",
    "print(f\"   Failed: {failed_samples} ({failed_samples/len(X_batch)*100:.1f}%)\")\n",
    "print(f\"   Total time: {total_execution_time:.2f} seconds\")\n",
    "print(f\"   Avg time per sample: {total_execution_time/len(X_batch):.2f} seconds\")\n",
    "print(f\"   Final results shape: {hardware_predictions.shape}\")\n",
    "\n",
    "print(f\"\\nðŸ†” Individual Job IDs:\")\n",
    "for i, job_info in enumerate(job_metadata['individual_jobs']):\n",
    "    job_id = job_info.get('job_id', 'N/A')\n",
    "    success = job_info.get('success', False)\n",
    "    status_icon = 'âœ…' if success else 'âŒ'\n",
    "    print(f\"   Sample {i+1}: {status_icon} {job_id}\")\n",
    "\n",
    "if failed_samples > 0:\n",
    "    error_1251_count = sum(1 for job in job_metadata['individual_jobs'] if job.get('error_category') == 'IBM_PREPROCESSING_ERROR_1251')\n",
    "    other_error_count = failed_samples - error_1251_count\n",
    "    \n",
    "    print(f\"\\nðŸ” ERROR BREAKDOWN:\")\n",
    "    print(f\"   IBM Error 1251 (preprocessing): {error_1251_count}\")\n",
    "    print(f\"   Other errors: {other_error_count}\")\n",
    "    \n",
    "    if error_1251_count > 0:\n",
    "        print(f\"\\nðŸ’¡ IBM Error 1251 Info:\")\n",
    "        print(f\"   This error typically occurs when the backend is overloaded or has issues.\")\n",
    "        print(f\"   Solutions: Try different backend, wait and retry, or use smaller batches.\")\n",
    "\n",
    "print(f\"\\nâœ… Hardware results obtained: {hardware_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "calibration",
   "metadata": {},
   "source": [
    "## Calibration Matrix Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3973d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Calibration matrix loaded: (16, 16)\n",
      "   Matrix range: [-0.330, 1.421]\n",
      "ðŸ”§ Applying calibration matrix to hardware predictions...\n",
      "âœ… Calibration applied successfully\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m calibrated_predictions = apply_calibration_matrix(hardware_predictions, calibration_matrix)\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Calibration applied successfully\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Original predictions shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mhardware_predictions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Calibrated predictions shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalibrated_predictions.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Calibration effect: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(np.abs(hardware_predictions\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mcalibrated_predictions))\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m average change\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Lod calibration matrix\n",
    "try:\n",
    "    calibration_matrix = pd.read_csv(CALIBRATION_MATRIX_PATH, header=None).values\n",
    "    print(f\"âœ… Calibration matrix loaded: {calibration_matrix.shape}\")\n",
    "    print(f\"   Matrix range: [{calibration_matrix.min():.3f}, {calibration_matrix.max():.3f}]\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading calibration matrix: {e}\")\n",
    "    # Create dummy calibration matrix\n",
    "    calibration_matrix = np.eye(16) + np.random.normal(0, 0.1, (16, 16))\n",
    "    print(\"âš ï¸ Using dummy calibration matrix\")\n",
    "\n",
    "def apply_calibration_matrix(raw_predictions, calibration_matrix):\n",
    "    \"\"\"\n",
    "    Apply calibration matrix to hardware predictions to get pseudo-ideal results\n",
    "    \n",
    "    Args:\n",
    "        raw_predictions: Hardware predictions (samples, time_steps)\n",
    "        calibration_matrix: 16x16 calibration matrix\n",
    "    \n",
    "    Returns:\n",
    "        calibrated_predictions: Pseudo-ideal predictions\n",
    "    \"\"\"\n",
    "    calibrated_predictions = []\n",
    "    \n",
    "    for sample_idx, sample_pred in enumerate(raw_predictions):\n",
    "        # Reshape predictions to work with 16x16 matrix\n",
    "        # 72 time steps -> need to map to 16 dimensions\n",
    "        # Simple approach: group into 16 bins\n",
    "        \n",
    "        sample_calibrated = []\n",
    "        for t in range(len(sample_pred)):\n",
    "            # Map time step to calibration matrix index (0-15)\n",
    "            matrix_idx = t % 16\n",
    "            \n",
    "            # Apply calibration row\n",
    "            raw_val = sample_pred[t]\n",
    "            calibration_row = calibration_matrix[matrix_idx]\n",
    "            \n",
    "            # Simple linear calibration: weighted sum\n",
    "            # For binary predictions, use the first element as base correction\n",
    "            calibrated_val = raw_val * calibration_row[0]\n",
    "            \n",
    "            # Apply threshold\n",
    "            calibrated_pred = 1 if calibrated_val > 0.5 else 0\n",
    "            sample_calibrated.append(calibrated_pred)\n",
    "            \n",
    "        calibrated_predictions.append(sample_calibrated)\n",
    "    \n",
    "    return np.array(calibrated_predictions)\n",
    "\n",
    "# Apply calibration\n",
    "print(\"ðŸ”§ Applying calibration matrix to hardware predictions...\")\n",
    "calibrated_predictions = apply_calibration_matrix(hardware_predictions, calibration_matrix)\n",
    "\n",
    "print(f\"âœ… Calibration applied successfully\")\n",
    "print(f\"   Original predictions shape: {hardware_predictions.shape}\")\n",
    "print(f\"   Calibrated predictions shape: {calibrated_predictions.shape}\")\n",
    "print(f\"   Calibration effect: {np.mean(np.abs(hardware_predictions - calibrated_predictions)):.3f} average change\")\n",
    "\n",
    "# Optional: Show some statistics about the calibration effect\n",
    "print(f\"\\nðŸ“Š Calibration Statistics:\")\n",
    "print(f\"   Samples where calibration changed predictions: {np.sum(hardware_predictions != calibrated_predictions)} / {hardware_predictions.size}\")\n",
    "print(f\"   Percentage of predictions changed: {np.mean(hardware_predictions != calibrated_predictions) * 100:.1f}%\")\n",
    "\n",
    "# Show per-sample calibration effect\n",
    "calibration_changes_per_sample = np.mean(np.abs(hardware_predictions - calibrated_predictions), axis=1)\n",
    "print(f\"   Average change per sample: min={calibration_changes_per_sample.min():.3f}, max={calibration_changes_per_sample.max():.3f}, mean={calibration_changes_per_sample.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble",
   "metadata": {},
   "source": [
    "## Ensemble Voting System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ensemble_voting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading ALL saved samples for comprehensive analysis...\n",
      "ðŸ“Š Found 260 total saved samples\n",
      "ðŸ“‹ All samples data shapes:\n",
      "   Hardware predictions: (260, 72)\n",
      "   Ground truth: (260, 72)\n",
      "   Hardware probabilities: (260, 72)\n",
      "\n",
      "ðŸ”§ Applying calibration to all 260 samples...\n",
      "ðŸ”§ Applying calibration to all probabilities...\n",
      "âœ… Calibration applied to all 260 samples\n",
      "   Average prediction change: 0.5410\n",
      "\n",
      "ðŸ—³ï¸  ENSEMBLE VOTING ON ALL 260 SAMPLES:\n",
      "âœ… Ensemble voting completed on all samples\n",
      "   Available strategies: ['consensus', 'equal_weight', 'hardware_preference', 'calibration_preference', 'conservative', 'liberal', 'confidence_based', 'confidence_weighted']\n",
      "\n",
      "ðŸ“Š INDIVIDUAL MODEL METRICS (ALL 260 samples):\n",
      "   Hardware (Raw) - All Samples:\n",
      "     accuracy: 0.7477\n",
      "     precision: 0.7651\n",
      "     recall: 0.7941\n",
      "     f1_score: 0.7793\n",
      "   Hardware (Calibrated) - All Samples:\n",
      "     accuracy: 0.4605\n",
      "     precision: 0.7617\n",
      "     recall: 0.0560\n",
      "     f1_score: 0.1043\n",
      "\n",
      "ðŸ¤ AGREEMENT PATTERNS (ALL 260 samples):\n",
      "   total_agreement: 45.9%\n",
      "   total_disagreement: 54.1%\n",
      "   agree_on_positive: 4.1%\n",
      "   agree_on_negative: 41.8%\n",
      "   hw_positive_cal_negative: 54.1%\n",
      "   hw_negative_cal_positive: 0.0%\n",
      "\n",
      "ðŸ“ˆ Voting Strategy Results (ALL 260 samples):\n",
      "   consensus                : accuracy=0.4605 (vs best individual: -0.2872)\n",
      "   equal_weight             : accuracy=0.4605 (vs best individual: -0.2872)\n",
      "   hardware_preference      : accuracy=0.7477 (vs best individual: +0.0000)\n",
      "   calibration_preference   : accuracy=0.4605 (vs best individual: -0.2872)\n",
      "   conservative             : accuracy=0.4605 (vs best individual: -0.2872)\n",
      "   liberal                  : accuracy=0.7477 (vs best individual: +0.0000)\n",
      "   confidence_based         : accuracy=0.4605 (vs best individual: -0.2872)\n",
      "   confidence_weighted      : accuracy=0.4604 (vs best individual: -0.2873)\n",
      "\n",
      "ðŸ† BEST VOTING STRATEGY (ALL 260 samples): hardware_preference\n",
      "   Accuracy: 0.7477\n",
      "   Precision: 0.7651\n",
      "   Recall: 0.7941\n",
      "   F1-Score: 0.7793\n",
      "   vs Best Individual: +0.0000\n",
      "\n",
      "ðŸ“‹ COMPREHENSIVE SUMMARY:\n",
      "   Total samples analyzed: 260\n",
      "   Best individual model: 0.7477\n",
      "   Best voting strategy: hardware_preference (0.7477)\n",
      "   Overall improvement: +0.0000\n",
      "   âš ï¸  Individual models perform better on the full dataset\n",
      "\n",
      "ðŸ’¡ Note: Analysis performed on ALL 260 saved samples, not just current batch!\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”„ Loading ALL saved samples for comprehensive analysis...\")\n",
    "\n",
    "# Load all previously saved results\n",
    "if os.path.exists(RESULTS_FILE):\n",
    "    with open(RESULTS_FILE, 'rb') as f:\n",
    "        all_saved_data = pickle.load(f)\n",
    "    \n",
    "    # Extract ALL samples from saved data\n",
    "    all_batch_info = all_saved_data.get('batch_info', {})\n",
    "    all_predictions = all_saved_data.get('predictions', {})\n",
    "    all_probabilities = all_saved_data.get('probabilities', {})\n",
    "    all_ground_truth = all_saved_data.get('ground_truth', [])\n",
    "    \n",
    "    total_saved_samples = len(all_batch_info.get('sample_indices', []))\n",
    "    print(f\"ðŸ“Š Found {total_saved_samples} total saved samples\")\n",
    "    \n",
    "    if total_saved_samples > 0:\n",
    "        # Get ALL hardware predictions and ground truth\n",
    "        all_hardware_predictions = np.array(all_predictions.get('hardware_raw', []))\n",
    "        all_hardware_probabilities = np.array(all_probabilities.get('hardware', [])) if all_probabilities.get('hardware') else None\n",
    "        all_ground_truth_array = np.array(all_ground_truth)\n",
    "        \n",
    "        print(f\"ðŸ“‹ All samples data shapes:\")\n",
    "        print(f\"   Hardware predictions: {all_hardware_predictions.shape}\")\n",
    "        print(f\"   Ground truth: {all_ground_truth_array.shape}\")\n",
    "        if all_hardware_probabilities is not None:\n",
    "            print(f\"   Hardware probabilities: {all_hardware_probabilities.shape}\")\n",
    "        \n",
    "        # Apply calibration to ALL samples\n",
    "        print(f\"\\nðŸ”§ Applying calibration to all {total_saved_samples} samples...\")\n",
    "        \n",
    "        def apply_calibration_to_all_samples(hardware_predictions_list, calibration_matrix):\n",
    "            \"\"\"Apply calibration matrix to all hardware predictions\"\"\"\n",
    "            calibrated_predictions = []\n",
    "            \n",
    "            for sample_idx, sample_pred in enumerate(hardware_predictions_list):\n",
    "                sample_calibrated = []\n",
    "                \n",
    "                for t in range(len(sample_pred)):\n",
    "                    # Map time step to calibration matrix index (0-15)\n",
    "                    matrix_idx = t % 16\n",
    "                    \n",
    "                    # Apply calibration row\n",
    "                    raw_val = sample_pred[t]\n",
    "                    calibration_row = calibration_matrix[matrix_idx]\n",
    "                    \n",
    "                    # Simple linear calibration: weighted sum\n",
    "                    calibrated_val = raw_val * calibration_row[0]\n",
    "                    \n",
    "                    # Apply threshold\n",
    "                    calibrated_pred = 1 if calibrated_val > 0.5 else 0\n",
    "                    sample_calibrated.append(calibrated_pred)\n",
    "                    \n",
    "                calibrated_predictions.append(sample_calibrated)\n",
    "            \n",
    "            return np.array(calibrated_predictions)\n",
    "        \n",
    "        all_calibrated_predictions = apply_calibration_to_all_samples(all_hardware_predictions, calibration_matrix)\n",
    "        \n",
    "        # Apply calibration to probabilities if available\n",
    "        all_calibrated_probabilities = None\n",
    "        if all_hardware_probabilities is not None:\n",
    "            print(\"ðŸ”§ Applying calibration to all probabilities...\")\n",
    "            all_calibrated_probabilities = apply_calibration_to_all_samples(all_hardware_probabilities, calibration_matrix)\n",
    "        \n",
    "        print(f\"âœ… Calibration applied to all {total_saved_samples} samples\")\n",
    "        print(f\"   Average prediction change: {np.mean(np.abs(all_hardware_predictions - all_calibrated_predictions)):.4f}\")\n",
    "        \n",
    "        # Define comprehensive voting strategies for all samples\n",
    "        def comprehensive_voting_strategies_all(hardware_preds, calibrated_preds, hardware_probs=None, calibrated_probs=None):\n",
    "            \"\"\"Apply voting strategies to all samples\"\"\"\n",
    "            \n",
    "            # Ensure inputs are numpy arrays with integer type\n",
    "            hardware_preds = np.array(hardware_preds, dtype=int)\n",
    "            calibrated_preds = np.array(calibrated_preds, dtype=int)\n",
    "            \n",
    "            strategies = {}\n",
    "            \n",
    "            # Strategy 1: Simple consensus (both must agree for positive)\n",
    "            strategies['consensus'] = ((hardware_preds + calibrated_preds) >= 2).astype(int)\n",
    "            \n",
    "            # Strategy 2: Equal weight voting\n",
    "            strategies['equal_weight'] = ((0.5 * hardware_preds + 0.5 * calibrated_preds) > 0.5).astype(int)\n",
    "            \n",
    "            # Strategy 3: Hardware preference (use hardware when they disagree)\n",
    "            strategies['hardware_preference'] = np.where(hardware_preds == calibrated_preds, \n",
    "                                                       hardware_preds, hardware_preds)\n",
    "            \n",
    "            # Strategy 4: Calibration preference (use calibrated when they disagree)\n",
    "            strategies['calibration_preference'] = np.where(hardware_preds == calibrated_preds,\n",
    "                                                          hardware_preds, calibrated_preds)\n",
    "            \n",
    "            # Strategy 5: Conservative (only positive if both predict positive)\n",
    "            strategies['conservative'] = (hardware_preds & calibrated_preds).astype(int)\n",
    "            \n",
    "            # Strategy 6: Liberal (positive if either predicts positive)\n",
    "            strategies['liberal'] = (hardware_preds | calibrated_preds).astype(int)\n",
    "            \n",
    "            # If probabilities are available, add confidence-based strategies\n",
    "            if hardware_probs is not None and calibrated_probs is not None:\n",
    "                # Strategy 7: Confidence-based voting\n",
    "                hw_confidence = np.abs(hardware_probs - 0.5)\n",
    "                cal_confidence = np.abs(calibrated_probs - 0.5)\n",
    "                \n",
    "                confidence_based = np.where(hw_confidence >= cal_confidence, \n",
    "                                          hardware_preds, calibrated_preds)\n",
    "                strategies['confidence_based'] = confidence_based\n",
    "                \n",
    "                # Strategy 8: Weighted by confidence\n",
    "                total_conf = hw_confidence + cal_confidence + 1e-8\n",
    "                weighted_probs = (hardware_probs * hw_confidence + calibrated_probs * cal_confidence) / total_conf\n",
    "                strategies['confidence_weighted'] = (weighted_probs > 0.5).astype(int)\n",
    "            \n",
    "            return strategies\n",
    "        \n",
    "        # Apply voting strategies to ALL samples\n",
    "        print(f\"\\nðŸ—³ï¸  ENSEMBLE VOTING ON ALL {total_saved_samples} SAMPLES:\")\n",
    "        all_voting_results = comprehensive_voting_strategies_all(\n",
    "            all_hardware_predictions, all_calibrated_predictions,\n",
    "            all_hardware_probabilities, all_calibrated_probabilities\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Ensemble voting completed on all samples\")\n",
    "        print(f\"   Available strategies: {list(all_voting_results.keys())}\")\n",
    "        \n",
    "        # Calculate individual model metrics for ALL samples\n",
    "        print(f\"\\nðŸ“Š INDIVIDUAL MODEL METRICS (ALL {total_saved_samples} samples):\")\n",
    "        \n",
    "        def calculate_metrics(y_true, y_pred):\n",
    "            \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "            y_true_flat = y_true.flatten()\n",
    "            y_pred_flat = y_pred.flatten()\n",
    "            return {\n",
    "                'accuracy': float(accuracy_score(y_true_flat, y_pred_flat)),\n",
    "                'precision': float(precision_score(y_true_flat, y_pred_flat, average='binary', zero_division=0)),\n",
    "                'recall': float(recall_score(y_true_flat, y_pred_flat, average='binary', zero_division=0)),\n",
    "                'f1_score': float(f1_score(y_true_flat, y_pred_flat, average='binary', zero_division=0))\n",
    "            }\n",
    "        \n",
    "        all_hardware_metrics = calculate_metrics(all_ground_truth_array, all_hardware_predictions)\n",
    "        all_calibrated_metrics = calculate_metrics(all_ground_truth_array, all_calibrated_predictions)\n",
    "        \n",
    "        print(\"   Hardware (Raw) - All Samples:\")\n",
    "        for metric, value in all_hardware_metrics.items():\n",
    "            print(f\"     {metric}: {value:.4f}\")\n",
    "        \n",
    "        print(\"   Hardware (Calibrated) - All Samples:\")\n",
    "        for metric, value in all_calibrated_metrics.items():\n",
    "            print(f\"     {metric}: {value:.4f}\")\n",
    "        \n",
    "        # Analyze agreement patterns for all samples\n",
    "        print(f\"\\nðŸ¤ AGREEMENT PATTERNS (ALL {total_saved_samples} samples):\")\n",
    "        \n",
    "        agree_all = (all_hardware_predictions == all_calibrated_predictions)\n",
    "        disagree_all = ~agree_all\n",
    "        agree_positive_all = agree_all & (all_hardware_predictions == 1)\n",
    "        agree_negative_all = agree_all & (all_hardware_predictions == 0)\n",
    "        hw_pos_cal_neg_all = disagree_all & (all_hardware_predictions == 1) & (all_calibrated_predictions == 0)\n",
    "        hw_neg_cal_pos_all = disagree_all & (all_hardware_predictions == 0) & (all_calibrated_predictions == 1)\n",
    "        \n",
    "        agreement_patterns_all = {\n",
    "            'total_agreement': float(agree_all.mean()),\n",
    "            'total_disagreement': float(disagree_all.mean()),\n",
    "            'agree_on_positive': float(agree_positive_all.mean()),\n",
    "            'agree_on_negative': float(agree_negative_all.mean()),\n",
    "            'hw_positive_cal_negative': float(hw_pos_cal_neg_all.mean()),\n",
    "            'hw_negative_cal_positive': float(hw_neg_cal_pos_all.mean())\n",
    "        }\n",
    "        \n",
    "        for pattern, value in agreement_patterns_all.items():\n",
    "            print(f\"   {pattern}: {value:.1%}\")\n",
    "        \n",
    "        # Evaluate voting strategies on ALL samples\n",
    "        all_voting_metrics = {}\n",
    "        best_individual_acc_all = max(all_hardware_metrics['accuracy'], all_calibrated_metrics['accuracy'])\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Voting Strategy Results (ALL {total_saved_samples} samples):\")\n",
    "        for strategy_name, strategy_preds in all_voting_results.items():\n",
    "            metrics = calculate_metrics(all_ground_truth_array, strategy_preds)\n",
    "            all_voting_metrics[strategy_name] = metrics\n",
    "            \n",
    "            improvement = metrics['accuracy'] - best_individual_acc_all\n",
    "            print(f\"   {strategy_name:25s}: accuracy={metrics['accuracy']:.4f} \"\n",
    "                  f\"(vs best individual: {improvement:+.4f})\")\n",
    "            \n",
    "            if improvement > 0:\n",
    "                print(f\"      âœ… IMPROVEMENT: {improvement*100:.2f}% better!\")\n",
    "        \n",
    "        # Find best strategy for all samples\n",
    "        best_strategy_all = max(all_voting_metrics.items(), key=lambda x: x[1]['accuracy'])\n",
    "        best_name_all = best_strategy_all[0]\n",
    "        best_metrics_all = best_strategy_all[1]\n",
    "        \n",
    "        print(f\"\\nðŸ† BEST VOTING STRATEGY (ALL {total_saved_samples} samples): {best_name_all}\")\n",
    "        print(f\"   Accuracy: {best_metrics_all['accuracy']:.4f}\")\n",
    "        print(f\"   Precision: {best_metrics_all['precision']:.4f}\")\n",
    "        print(f\"   Recall: {best_metrics_all['recall']:.4f}\")\n",
    "        print(f\"   F1-Score: {best_metrics_all['f1_score']:.4f}\")\n",
    "        print(f\"   vs Best Individual: {best_metrics_all['accuracy'] - best_individual_acc_all:+.4f}\")\n",
    "        \n",
    "        # Update ensemble results with ALL samples results\n",
    "        ensemble_results = all_voting_results\n",
    "        ensemble_accuracies = {k: v['accuracy'] for k, v in all_voting_metrics.items()}\n",
    "        best_strategy = (best_name_all, best_metrics_all['accuracy'])\n",
    "        \n",
    "        # Update individual accuracies to reflect ALL samples\n",
    "        hardware_acc = all_hardware_metrics['accuracy']\n",
    "        calibrated_acc = all_calibrated_metrics['accuracy']\n",
    "        \n",
    "        # Final summary\n",
    "        print(f\"\\nðŸ“‹ COMPREHENSIVE SUMMARY:\")\n",
    "        print(f\"   Total samples analyzed: {total_saved_samples}\")\n",
    "        print(f\"   Best individual model: {best_individual_acc_all:.4f}\")\n",
    "        print(f\"   Best voting strategy: {best_name_all} ({best_metrics_all['accuracy']:.4f})\")\n",
    "        print(f\"   Overall improvement: {best_metrics_all['accuracy'] - best_individual_acc_all:+.4f}\")\n",
    "        \n",
    "        if best_metrics_all['accuracy'] > best_individual_acc_all:\n",
    "            improvement_pct = (best_metrics_all['accuracy'] - best_individual_acc_all) * 100\n",
    "            print(f\"   âœ… Voting is BETTER by {improvement_pct:.2f}%!\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸  Individual models perform better on the full dataset\")\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ Note: Analysis performed on ALL {total_saved_samples} saved samples, not just current batch!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No saved samples found for comprehensive analysis\")\n",
    "        print(\"ðŸ”„ Falling back to current batch analysis...\")\n",
    "        \n",
    "        # Fallback to current batch only (your original voting code)\n",
    "        def ensemble_voting_strategies(hardware_preds, calibrated_preds):\n",
    "            \"\"\"Apply different ensemble voting strategies\"\"\"\n",
    "            \n",
    "            strategies = {}\n",
    "            \n",
    "            # Strategy 1: Simple majority voting (hardware + calibrated)\n",
    "            majority_sum = hardware_preds + calibrated_preds\n",
    "            strategies['simple_majority'] = (majority_sum >= 2).astype(int)\n",
    "            \n",
    "            # Strategy 2: Weighted voting \n",
    "            weighted = 0.5 * calibrated_preds + 0.5 * hardware_preds\n",
    "            strategies['weighted'] = (weighted > 0.5).astype(int)\n",
    "            \n",
    "            return strategies\n",
    "        \n",
    "        # Apply ensemble voting on current batch\n",
    "        print(\"ðŸ—³ï¸ Applying ensemble voting strategies...\")\n",
    "        ensemble_results = ensemble_voting_strategies(\n",
    "            hardware_predictions.astype(int), \n",
    "            calibrated_predictions\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Ensemble voting completed\")\n",
    "        print(f\"   Available strategies: {list(ensemble_results.keys())}\")\n",
    "        \n",
    "        # Evaluate ensemble strategies\n",
    "        y_batch_flat = y_batch.flatten()\n",
    "        ensemble_accuracies = {}\n",
    "        \n",
    "        print(\"\\nðŸ“Š Ensemble Strategy Accuracies:\")\n",
    "        for strategy_name, predictions in ensemble_results.items():\n",
    "            accuracy = accuracy_score(y_batch_flat, predictions.flatten())\n",
    "            ensemble_accuracies[strategy_name] = accuracy\n",
    "            print(f\"   {strategy_name:20s}: {accuracy:.4f}\")\n",
    "        \n",
    "        # Individual model accuracies for comparison\n",
    "        hardware_acc = accuracy_score(y_batch_flat, hardware_predictions.flatten())\n",
    "        calibrated_acc = accuracy_score(y_batch_flat, calibrated_predictions.flatten())\n",
    "        \n",
    "        print(\"\\nðŸ“ˆ Individual Model Accuracies:\")\n",
    "        print(f\"   Hardware (raw):      {hardware_acc:.4f}\")\n",
    "        print(f\"   Calibrated:          {calibrated_acc:.4f}\")\n",
    "        \n",
    "        # Find best strategy\n",
    "        best_strategy = max(ensemble_accuracies.items(), key=lambda x: x[1])\n",
    "        print(f\"\\nðŸ† Best ensemble strategy: {best_strategy[0]} with accuracy {best_strategy[1]:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No saved results file found!\")\n",
    "    print(\"ðŸ”„ Proceeding with current batch analysis only...\")\n",
    "    \n",
    "    # Fallback to current batch analysis (original code)\n",
    "    def ensemble_voting_strategies(hardware_preds, calibrated_preds):\n",
    "        \"\"\"Apply different ensemble voting strategies\"\"\"\n",
    "        \n",
    "        strategies = {}\n",
    "        \n",
    "        # Strategy 1: Simple majority voting (hardware + calibrated)\n",
    "        majority_sum = hardware_preds + calibrated_preds\n",
    "        strategies['simple_majority'] = (majority_sum >= 2).astype(int)\n",
    "        \n",
    "        # Strategy 2: Weighted voting \n",
    "        weighted = 0.5 * calibrated_preds + 0.5 * hardware_preds\n",
    "        strategies['weighted'] = (weighted > 0.5).astype(int)\n",
    "        \n",
    "        return strategies\n",
    "    \n",
    "    # Apply ensemble voting\n",
    "    print(\"ðŸ—³ï¸ Applying ensemble voting strategies...\")\n",
    "    ensemble_results = ensemble_voting_strategies(\n",
    "        hardware_predictions.astype(int), \n",
    "        calibrated_predictions\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Ensemble voting completed\")\n",
    "    print(f\"   Available strategies: {list(ensemble_results.keys())}\")\n",
    "    \n",
    "    # Evaluate ensemble strategies\n",
    "    y_batch_flat = y_batch.flatten()\n",
    "    ensemble_accuracies = {}\n",
    "    \n",
    "    print(\"\\nðŸ“Š Ensemble Strategy Accuracies:\")\n",
    "    for strategy_name, predictions in ensemble_results.items():\n",
    "        accuracy = accuracy_score(y_batch_flat, predictions.flatten())\n",
    "        ensemble_accuracies[strategy_name] = accuracy\n",
    "        print(f\"   {strategy_name:20s}: {accuracy:.4f}\")\n",
    "    \n",
    "    # Individual model accuracies for comparison\n",
    "    hardware_acc = accuracy_score(y_batch_flat, hardware_predictions.flatten())\n",
    "    calibrated_acc = accuracy_score(y_batch_flat, calibrated_predictions.flatten())\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Individual Model Accuracies:\")\n",
    "    print(f\"   Hardware (raw):      {hardware_acc:.4f}\")\n",
    "    print(f\"   Calibrated:          {calibrated_acc:.4f}\")\n",
    "    \n",
    "    # Find best strategy\n",
    "    best_strategy = max(ensemble_accuracies.items(), key=lambda x: x[1])\n",
    "    print(f\"\\nðŸ† Best ensemble strategy: {best_strategy[0]} with accuracy {best_strategy[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-saving",
   "metadata": {},
   "source": [
    "## Save Results and Job Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "save_results",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mThis fixes the dict + dict error when adding new batches\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Prepare comprehensive results\u001b[39;00m\n\u001b[32m      7\u001b[39m results = {\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbatch_info\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mstart_sample\u001b[39m\u001b[33m'\u001b[39m: START_SAMPLE,\n\u001b[32m     10\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mend_sample\u001b[39m\u001b[33m'\u001b[39m: END_SAMPLE,\n\u001b[32m     11\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msample_indices\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(START_SAMPLE, END_SAMPLE)),\n\u001b[32m     12\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlocations\u001b[39m\u001b[33m'\u001b[39m: loc_batch.tolist(),\n\u001b[32m     13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m: datetime.now().isoformat()\n\u001b[32m     14\u001b[39m     },\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mhardware_raw\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mhardware_predictions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m(),\n\u001b[32m     17\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mhardware_calibrated\u001b[39m\u001b[33m'\u001b[39m: calibrated_predictions.tolist(),\n\u001b[32m     18\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mensemble_strategies\u001b[39m\u001b[33m'\u001b[39m: {k: v.tolist() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ensemble_results.items()}\n\u001b[32m     19\u001b[39m     },\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprobabilities\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     21\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mhardware\u001b[39m\u001b[33m'\u001b[39m: hardware_probabilities.tolist(),\n\u001b[32m     22\u001b[39m     },\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m'\u001b[39m: y_batch.tolist(),\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maccuracies\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     25\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mhardware_raw\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(hardware_acc),\n\u001b[32m     26\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mhardware_calibrated\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(calibrated_acc),\n\u001b[32m     27\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mensemble_strategies\u001b[39m\u001b[33m'\u001b[39m: ensemble_accuracies,\n\u001b[32m     28\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mbest_strategy\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     29\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: best_strategy[\u001b[32m0\u001b[39m],\n\u001b[32m     30\u001b[39m             \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(best_strategy[\u001b[32m1\u001b[39m])\n\u001b[32m     31\u001b[39m         }\n\u001b[32m     32\u001b[39m     },\n\u001b[32m     33\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcalibration_info\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     34\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmatrix_shape\u001b[39m\u001b[33m'\u001b[39m: calibration_matrix.shape,\n\u001b[32m     35\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmatrix_applied\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     36\u001b[39m         \u001b[33m'\u001b[39m\u001b[33maverage_change\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(np.mean(np.abs(hardware_predictions - calibrated_predictions)))\n\u001b[32m     37\u001b[39m     }\n\u001b[32m     38\u001b[39m }\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Update job metadata\u001b[39;00m\n\u001b[32m     41\u001b[39m job_metadata[\u001b[33m'\u001b[39m\u001b[33mresults_summary\u001b[39m\u001b[33m'\u001b[39m] = {\n\u001b[32m     42\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msamples_processed\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(X_batch),\n\u001b[32m     43\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_ensemble_accuracy\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(best_strategy[\u001b[32m1\u001b[39m]),\n\u001b[32m     44\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhardware_accuracy\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(hardware_acc),\n\u001b[32m     45\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimprovement_over_hardware\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(best_strategy[\u001b[32m1\u001b[39m] - hardware_acc)\n\u001b[32m     46\u001b[39m }\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "# Fixed Save Results Cell - Replace the existing save_results cell with this\n",
    "\"\"\"\n",
    "This fixes the dict + dict error when adding new batches\n",
    "\"\"\"\n",
    "\n",
    "# Prepare comprehensive results\n",
    "results = {\n",
    "    'batch_info': {\n",
    "        'start_sample': START_SAMPLE,\n",
    "        'end_sample': END_SAMPLE,\n",
    "        'sample_indices': list(range(START_SAMPLE, END_SAMPLE)),\n",
    "        'locations': loc_batch.tolist(),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    },\n",
    "    'predictions': {\n",
    "        'hardware_raw': hardware_predictions.tolist(),\n",
    "        'hardware_calibrated': calibrated_predictions.tolist(),\n",
    "        'ensemble_strategies': {k: v.tolist() for k, v in ensemble_results.items()}\n",
    "    },\n",
    "    'probabilities': {\n",
    "        'hardware': hardware_probabilities.tolist(),\n",
    "    },\n",
    "    'ground_truth': y_batch.tolist(),\n",
    "    'accuracies': {\n",
    "        'hardware_raw': float(hardware_acc),\n",
    "        'hardware_calibrated': float(calibrated_acc),\n",
    "        'ensemble_strategies': ensemble_accuracies,\n",
    "        'best_strategy': {\n",
    "            'name': best_strategy[0],\n",
    "            'accuracy': float(best_strategy[1])\n",
    "        }\n",
    "    },\n",
    "    'calibration_info': {\n",
    "        'matrix_shape': calibration_matrix.shape,\n",
    "        'matrix_applied': True,\n",
    "        'average_change': float(np.mean(np.abs(hardware_predictions - calibrated_predictions)))\n",
    "    }\n",
    "}\n",
    "\n",
    "# Update job metadata\n",
    "job_metadata['results_summary'] = {\n",
    "    'samples_processed': len(X_batch),\n",
    "    'best_ensemble_accuracy': float(best_strategy[1]),\n",
    "    'hardware_accuracy': float(hardware_acc),\n",
    "    'improvement_over_hardware': float(best_strategy[1] - hardware_acc)\n",
    "}\n",
    "\n",
    "# Handle continuation: load existing results if they exist\n",
    "if os.path.exists(RESULTS_FILE) and START_SAMPLE > 0:\n",
    "    print(f\"ðŸ“‚ Loading existing results for continuation...\")\n",
    "    with open(RESULTS_FILE, 'rb') as f:\n",
    "        existing_results = pickle.load(f)\n",
    "    \n",
    "    # Get existing data\n",
    "    existing_batch_info = existing_results.get('batch_info', {})\n",
    "    existing_predictions = existing_results.get('predictions', {})\n",
    "    existing_probabilities = existing_results.get('probabilities', {})\n",
    "    existing_ground_truth = existing_results.get('ground_truth', [])\n",
    "    \n",
    "    print(f\"   Existing samples: {len(existing_batch_info.get('sample_indices', []))}\")\n",
    "    \n",
    "    # FIXED: Properly combine results without dict + dict error\n",
    "    combined_results = {\n",
    "        'batch_info': {\n",
    "            'start_sample': 0,  # Overall start\n",
    "            'end_sample': END_SAMPLE,  # Current end\n",
    "            'sample_indices': existing_batch_info.get('sample_indices', []) + results['batch_info']['sample_indices'],\n",
    "            'locations': existing_batch_info.get('locations', []) + results['batch_info']['locations'],\n",
    "            'timestamp': results['batch_info']['timestamp'],\n",
    "            'batches_processed': existing_batch_info.get('batches_processed', 1) + 1\n",
    "        },\n",
    "        'predictions': {},\n",
    "        'probabilities': {},\n",
    "        'ground_truth': existing_ground_truth + results['ground_truth'],\n",
    "        'accuracies': results['accuracies'],  # Keep latest batch accuracies\n",
    "        'calibration_info': results['calibration_info']\n",
    "    }\n",
    "    \n",
    "    # FIXED: Combine predictions properly\n",
    "    for key in ['hardware_raw', 'hardware_calibrated']:\n",
    "        if key in existing_predictions and key in results['predictions']:\n",
    "            combined_results['predictions'][key] = existing_predictions[key] + results['predictions'][key]\n",
    "        elif key in results['predictions']:\n",
    "            combined_results['predictions'][key] = results['predictions'][key]\n",
    "        elif key in existing_predictions:\n",
    "            combined_results['predictions'][key] = existing_predictions[key]\n",
    "    \n",
    "    # FIXED: Combine ensemble strategies properly\n",
    "    combined_ensemble = {}\n",
    "    existing_ensemble = existing_predictions.get('ensemble_strategies', {})\n",
    "    new_ensemble = results['predictions']['ensemble_strategies']\n",
    "    \n",
    "    # Get all strategy names\n",
    "    all_strategies = set(list(existing_ensemble.keys()) + list(new_ensemble.keys()))\n",
    "    \n",
    "    for strategy in all_strategies:\n",
    "        existing_strategy_data = existing_ensemble.get(strategy, [])\n",
    "        new_strategy_data = new_ensemble.get(strategy, [])\n",
    "        combined_ensemble[strategy] = existing_strategy_data + new_strategy_data\n",
    "    \n",
    "    combined_results['predictions']['ensemble_strategies'] = combined_ensemble\n",
    "    \n",
    "    # FIXED: Combine probabilities properly\n",
    "    for key in results['probabilities']:\n",
    "        if key in existing_probabilities:\n",
    "            combined_results['probabilities'][key] = existing_probabilities[key] + results['probabilities'][key]\n",
    "        else:\n",
    "            combined_results['probabilities'][key] = results['probabilities'][key]\n",
    "    \n",
    "    results = combined_results\n",
    "    print(f\"   Combined total samples: {len(results['batch_info']['sample_indices'])}\")\n",
    "\n",
    "# Save results\n",
    "print(f\"ðŸ’¾ Saving results to {RESULTS_FILE}...\")\n",
    "with open(RESULTS_FILE, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "# Save job metadata\n",
    "if os.path.exists(JOB_METADATA_FILE):\n",
    "    with open(JOB_METADATA_FILE, 'r') as f:\n",
    "        existing_metadata = json.load(f)\n",
    "    \n",
    "    if 'job_history' not in existing_metadata:\n",
    "        existing_metadata['job_history'] = []\n",
    "    existing_metadata['job_history'].append(job_metadata)\n",
    "    existing_metadata['latest_batch'] = job_metadata\n",
    "    \n",
    "    with open(JOB_METADATA_FILE, 'w') as f:\n",
    "        json.dump(existing_metadata, f, indent=2)\n",
    "else:\n",
    "    metadata_to_save = {\n",
    "        'job_history': [job_metadata],\n",
    "        'latest_batch': job_metadata\n",
    "    }\n",
    "    with open(JOB_METADATA_FILE, 'w') as f:\n",
    "        json.dump(metadata_to_save, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Results saved successfully!\")\n",
    "print(f\"   Results file: {RESULTS_FILE}\")\n",
    "print(f\"   Metadata file: {JOB_METADATA_FILE}\")\n",
    "print(f\"   Total samples processed: {len(results['batch_info']['sample_indices'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuation-guide",
   "metadata": {},
   "source": [
    "## Continuation Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "### ðŸ”„ Running Next Batch\n",
    "\n",
    "To process the next 10 samples:\n",
    "\n",
    "1. **Modify Configuration Cell:**\n",
    "   ```python\n",
    "   START_SAMPLE = 10  # For second batch\n",
    "   END_SAMPLE = 20    # For second batch\n",
    "   ```\n",
    "\n",
    "2. **Run All Cells Again** - The notebook will automatically:\n",
    "   - Load existing results\n",
    "   - Process new samples\n",
    "   - Append to existing results\n",
    "   - Update job metadata\n",
    "\n",
    "3. **For Subsequent Batches:**\n",
    "   - Third batch: START_SAMPLE=20, END_SAMPLE=30\n",
    "   - Fourth batch: START_SAMPLE=30, END_SAMPLE=40\n",
    "   - And so on...\n",
    "\n",
    "### ðŸ“Š Checking Progress\n",
    "Your results are automatically saved and can be analyzed at any time using the saved pickle and JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "summary_stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "           BATCH 26 COMPLETION SUMMARY\n",
      "============================================================\n",
      "Samples processed this batch: 50\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSamples processed this batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_SAMPLE\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mSTART_SAMPLE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal samples processed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mresults\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mbatch_info\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33msample_indices\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBackend used: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBACKEND_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest ensemble strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_strategy[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"           BATCH {START_SAMPLE//10 + 1} COMPLETION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Samples processed this batch: {END_SAMPLE - START_SAMPLE}\")\n",
    "print(f\"Total samples processed: {len(results['batch_info']['sample_indices'])}\")\n",
    "print(f\"Backend used: {BACKEND_NAME}\")\n",
    "print(f\"Best ensemble strategy: {best_strategy[0]}\")\n",
    "print(f\"Best ensemble accuracy: {best_strategy[1]:.4f}\")\n",
    "print(f\"Hardware improvement: {best_strategy[1] - hardware_acc:+.4f}\")\n",
    "print(\"\\nðŸŽ¯ Ready for next batch! Update START_SAMPLE and END_SAMPLE in config cell.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35649a09-92f0-40a8-80f7-da2972044b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec0781-d75a-4467-894c-46214a727b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
