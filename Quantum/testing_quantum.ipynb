{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19525ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'test_air_quality_data.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee754403",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "n_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa930590",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f466d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def q_circuit(inputs, weights):\n",
    "    \"\"\"A quantum circuit that acts as a feature extractor.\"\"\"\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cab11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid Quantum-Classical model for multi-step forecasting.\n",
    "    A classical LSTM processes the sequence, and its output is fed\n",
    "    into a quantum circuit for feature extraction, followed by a\n",
    "    classical layer for multi-step prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, n_lstm_units=4, n_qubits=2, num_layers=1, n_layers=1, output_len=72):\n",
    "        super(QLSTMModel, self).__init__()\n",
    "\n",
    "        # 1. Classical LSTM Layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=n_lstm_units,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # 2. Classical Layer to map LSTM output to Quantum input\n",
    "        self.classical_to_quantum = nn.Linear(n_lstm_units, n_qubits)\n",
    "        \n",
    "        # 3. Quantum Layer\n",
    "        weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n",
    "        self.q_layer = qml.qnn.TorchLayer(q_circuit, weight_shapes)\n",
    "        \n",
    "        # 4. Classical Layer to map quantum output to predictions\n",
    "        self.quantum_to_output = nn.Linear(n_qubits, output_len)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        # 1. Pass data through the classical LSTM\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # 2. Extract features from the last timestep\n",
    "        final_lstm_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # 3. Prepare the data for the quantum circuit\n",
    "        quantum_input = self.classical_to_quantum(final_lstm_output)\n",
    "        \n",
    "        # 4. Pass the features through the quantum circuit\n",
    "        quantum_features = self.q_layer(quantum_input)\n",
    "        \n",
    "        # 5. Map quantum features to output sequence\n",
    "        output = self.quantum_to_output(quantum_features)\n",
    "        \n",
    "        # 6. Apply sigmoid activation to get probabilities\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "110331b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(file_path, lat_bins, lon_bins, le_location):\n",
    "    \"\"\"Transform raw test data using saved preprocessing objects\"\"\"\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Use provided bins from training data\n",
    "    lat_positions = pd.cut(df['lat'], bins=lat_bins, labels=False, include_lowest=True)\n",
    "    lon_positions = pd.cut(df['lon'], bins=lon_bins, labels=False, include_lowest=True)\n",
    "    df['location'] = lat_positions * 20 + lon_positions\n",
    "    df['location'] = df['location'].fillna(0).astype(int)\n",
    "    \n",
    "    # Process class and time features\n",
    "    df['class'] = df['class'].isin(['Good', 'Moderate']).astype(int)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df['year'] = df['time'].dt.year\n",
    "    df['month'] = df['time'].dt.month\n",
    "    df['day'] = df['time'].dt.day\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    \n",
    "    # Select columns\n",
    "    list_of_columns = ['class', 'PM25_MERRA2', 'DUCMASS', 'TOTANGSTR', 'DUFLUXV', 'SSFLUXV', 'DUFLUXU', 'BCCMASS', 'SSSMASS25', 'location']\n",
    "    selected_columns = list_of_columns + ['year', 'month', 'day', 'hour']\n",
    "    df = df[selected_columns]\n",
    "    \n",
    "    # Encode location using saved encoder\n",
    "    df['location_encoded'] = df['location'].map(\n",
    "        lambda x: le_location.transform([x])[0] if x in le_location.classes_ else -1\n",
    "    )\n",
    "    \n",
    "    df = df.sort_values(['location_encoded', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    # Define feature columns\n",
    "    feature_columns = [col for col in df.columns if col not in [\n",
    "        'class', 'location', 'year', 'month', 'day', 'hour', 'location_encoded'\n",
    "    ]]\n",
    "    df.drop(columns='location', inplace=True)\n",
    "    feature_columns.append('location_encoded')\n",
    "    \n",
    "    return df, feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89061064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_memory_efficient(df, feature_columns, scaler, \n",
    "                                    input_len=168, output_len=72, stride=24):\n",
    "    \"\"\"Create sequences for testing using saved scaler\"\"\"\n",
    "    print(f\"Creating sequences with input length={input_len}, output length={output_len}...\")\n",
    "    \n",
    "    X_scaled = scaler.transform(df[feature_columns])\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=feature_columns, index=df.index)\n",
    "    \n",
    "    X_sequences, y_sequences, location_indices = [], [], []\n",
    "    unique_locations = df['location_encoded'].unique()\n",
    "\n",
    "    for i, loc in enumerate(unique_locations):\n",
    "        loc_df = df[df['location_encoded'] == loc]\n",
    "        loc_X = X_scaled.loc[loc_df.index]\n",
    "        loc_y = loc_df['class'].values\n",
    "\n",
    "        max_start_idx = len(loc_df) - input_len - output_len\n",
    "\n",
    "        for j in range(0, max_start_idx, stride):\n",
    "            X_seq = loc_X.iloc[j : j + input_len].values\n",
    "            y_target = loc_y[j + input_len : j + input_len + output_len]\n",
    "\n",
    "            X_sequences.append(X_seq)\n",
    "            y_sequences.append(y_target)\n",
    "            location_indices.append(loc)\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Processed location {i+1}/{len(unique_locations)}\")\n",
    "\n",
    "    X_sequences = np.array(X_sequences, dtype=np.float32)\n",
    "    y_sequences = np.array(y_sequences, dtype=np.float32)\n",
    "    location_indices = np.array(location_indices)\n",
    "\n",
    "    print(f\"Total sequences: {X_sequences.shape[0]}\")\n",
    "    print(f\"Input sequence shape: {X_sequences.shape}\")\n",
    "    print(f\"Output sequence shape: {y_sequences.shape}\")\n",
    "\n",
    "    return X_sequences, y_sequences, location_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b6848f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_predictions(model, X_test, y_test, num_examples=3):\n",
    "    \"\"\"Plot example predictions vs actual values\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sample_indices = np.random.choice(len(X_test), num_examples, replace=False)\n",
    "        plt.figure(figsize=(15, 5 * num_examples))\n",
    "\n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            X_sample = torch.tensor(X_test[idx:idx+1]).to(device)\n",
    "            y_true = y_test[idx]\n",
    "            y_pred = model(X_sample).cpu().numpy()[0]\n",
    "            y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "            plt.subplot(num_examples, 1, i+1)\n",
    "            hours = np.arange(1, 72 + 1)\n",
    "            plt.plot(hours, y_true, 'bo-', label='Actual')\n",
    "            plt.plot(hours, y_pred, 'ro--', label='Predicted')\n",
    "            plt.title(f'Example {i+1}: Air Quality Prediction (Next 72 Hours)')\n",
    "            plt.xlabel('Hours Ahead')\n",
    "            plt.ylabel('Air Quality Class')\n",
    "            plt.yticks([0, 1], ['Good', 'Poor'])\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('example_predictions.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_per_location_and_hour(model, test_loader, device, location_indices_test, output_seq_len=72):\n",
    "    \"\"\"\n",
    "    Evaluate the model with the needed metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            preds = (outputs > 0.5).float()\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    preds_flat, labels_flat = all_preds.flatten(), all_labels.flatten()\n",
    "\n",
    "    # All metrics Required\n",
    "    accuracy = (preds_flat == labels_flat).mean()\n",
    "    precision = precision_score(labels_flat, preds_flat, average=\"binary\")\n",
    "    recall = recall_score(labels_flat, preds_flat, average=\"binary\")\n",
    "    f1 = f1_score(labels_flat, preds_flat, average=\"binary\")\n",
    "    conf_matrix = confusion_matrix(labels_flat, preds_flat)\n",
    "\n",
    "    # Per-location metrics\n",
    "    unique_locations = np.unique(location_indices_test)\n",
    "    location_metrics = {}\n",
    "    for loc in unique_locations:\n",
    "        idx = (location_indices_test == loc)\n",
    "        preds_loc, labels_loc = all_preds[idx].flatten(), all_labels[idx].flatten()\n",
    "        location_metrics[int(loc)] = {\n",
    "            \"accuracy\": (preds_loc == labels_loc).mean(),\n",
    "            \"precision\": precision_score(labels_loc, preds_loc, average=\"binary\"),\n",
    "            \"recall\": recall_score(labels_loc, preds_loc, average=\"binary\"),\n",
    "            \"f1\": f1_score(labels_loc, preds_loc, average=\"binary\"),\n",
    "            \"confusion_matrix\": confusion_matrix(labels_loc, preds_loc)\n",
    "        }\n",
    "\n",
    "    # Per-hour metrics\n",
    "    hour_metrics = []\n",
    "    for hour in range(output_seq_len):\n",
    "        preds_hour, labels_hour = all_preds[:, hour], all_labels[:, hour]\n",
    "        hour_metrics.append({\n",
    "            \"hour\": hour + 1,\n",
    "            \"accuracy\": (preds_hour == labels_hour).mean(),\n",
    "            \"precision\": precision_score(labels_hour, preds_hour, average=\"binary\"),\n",
    "            \"recall\": recall_score(labels_hour, preds_hour, average=\"binary\"),\n",
    "            \"f1\": f1_score(labels_hour, preds_hour, average=\"binary\"),\n",
    "            \"confusion_matrix\": confusion_matrix(labels_hour, preds_hour)\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"overall\": {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"confusion_matrix\": conf_matrix\n",
    "        },\n",
    "        \"per_location\": location_metrics,\n",
    "        \"per_hour\": hour_metrics,\n",
    "        \"preds_flat\": preds_flat,  \n",
    "        \"labels_flat\": labels_flat  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a0400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0,1], yticklabels=[0,1])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf6be23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found GPU: NVIDIA GeForce RTX 3050 Laptop GPU. Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ Found GPU: {torch.cuda.get_device_name(0)}. Using CUDA.\")\n",
    "else:\n",
    "    print(\"❌ No GPU found. The script will run on the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbbadb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessing_state.pkl', 'rb') as f:\n",
    "    preprocessing_state = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dff00b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sequences with input length=168, output length=72...\n",
      "Processed location 100/400\n",
      "Processed location 200/400\n",
      "Processed location 300/400\n",
      "Processed location 400/400\n",
      "Total sequences: 79340\n",
      "Input sequence shape: (79340, 168, 9)\n",
      "Output sequence shape: (79340, 72)\n"
     ]
    }
   ],
   "source": [
    "lat_bins = preprocessing_state['lat_bins']\n",
    "lon_bins = preprocessing_state['lon_bins']\n",
    "le_location = preprocessing_state['le_location']\n",
    "feature_columns = preprocessing_state['feature_columns']\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "df, feature_columns = transform_data(test_data_path, lat_bins, lon_bins, le_location)\n",
    "\n",
    "X_test, y_test, location_indices = create_sequences_memory_efficient(\n",
    "    df, feature_columns, scaler, input_len=168, output_len=72, stride=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "651d90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a94cae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid Quantum-Classical LSTM Model Architecture:\n",
      "QLSTMModel(\n",
      "  (lstm): LSTM(9, 32, batch_first=True)\n",
      "  (classical_to_quantum): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (q_layer): <Quantum Torch Layer: func=q_circuit>\n",
      "  (quantum_to_output): Linear(in_features=4, out_features=72, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17873/2255449281.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_qlstm_model_multistep.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QLSTMModel(\n",
       "  (lstm): LSTM(9, 32, batch_first=True)\n",
       "  (classical_to_quantum): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (q_layer): <Quantum Torch Layer: func=q_circuit>\n",
       "  (quantum_to_output): Linear(in_features=4, out_features=72, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_lstm_units = 32\n",
    "num_layers = 1\n",
    "\n",
    "model = QLSTMModel(\n",
    "    n_features=len(feature_columns), \n",
    "    n_lstm_units=n_lstm_units,  \n",
    "    n_qubits=n_qubits,\n",
    "    num_layers=num_layers,\n",
    "    n_layers=n_layers,\n",
    "    output_len=72\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('best_qlstm_model_multistep.pth'))\n",
    "print(\"\\nHybrid Quantum-Classical LSTM Model Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Evaluate model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d8e9b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating detailed accuracy metrics...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCalculating detailed accuracy metrics...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m metrics  \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_per_location_and_hour\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation_indices\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m, in \u001b[0;36mevaluate_model_per_location_and_hour\u001b[0;34m(model, test_loader, device, location_indices_test, output_seq_len)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     10\u001b[0m     X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     preds \u001b[38;5;241m=\u001b[39m (outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     14\u001b[0m     all_preds\u001b[38;5;241m.\u001b[39mappend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[10], line 40\u001b[0m, in \u001b[0;36mQLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m quantum_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassical_to_quantum(final_lstm_output)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# 4. Pass the features through the quantum circuit\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m quantum_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantum_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 5. Map quantum features to output sequence\u001b[39;00m\n\u001b[1;32m     43\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantum_to_output(quantum_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/qnn/torch.py:408\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/qnn/torch.py:434\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m    433\u001b[0m }\n\u001b[0;32m--> 434\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/qnode.py:922\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/qnode.py:895\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m--> 895\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/execution.py:233\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[0m\n\u001b[1;32m    229\u001b[0m tapes, outer_post_processing \u001b[38;5;241m=\u001b[39m outer_transform(tapes)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outer_transform\u001b[38;5;241m.\u001b[39mis_informative, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould only contain device preprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_post_processing(outer_post_processing(results))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/run.py:338\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    335\u001b[0m         params \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    336\u001b[0m         tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_trainable_indices(params)\n\u001b[0;32m--> 338\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mml_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:240\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    232\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mextend(tape\u001b[38;5;241m.\u001b[39mget_parameters())\n\u001b[1;32m    234\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: execute_fn,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m: jpc,\n\u001b[1;32m    238\u001b[0m }\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:89\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_apply\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_apply\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     out_struct_holder \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 89\u001b[0m     flat_out \u001b[38;5;241m=\u001b[39m \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_out, out_struct_holder[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:93\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_forward\u001b[0;34m(ctx, out_struct_holder, *inp)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(ctx, out_struct_holder, \u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m---> 93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     flat_out, out_struct \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(out)\n\u001b[1;32m     95\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_out_struct \u001b[38;5;241m=\u001b[39m out_struct\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:162\u001b[0m, in \u001b[0;36mExecuteTapes.forward\u001b[0;34m(ctx, kwargs, *parameters)\u001b[0m\n\u001b[1;32m    159\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtapes \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m ctx\u001b[38;5;241m.\u001b[39mjpc \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 162\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[1;32m    165\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtorch_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/jacobian_products.py:487\u001b[0m, in \u001b[0;36mDeviceDerivatives.execute_and_cache_jacobian\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39misEnabledFor(logging\u001b[38;5;241m.\u001b[39mDEBUG):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward pass called with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, tapes)\n\u001b[0;32m--> 487\u001b[0m results, jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dev_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results_cache[tapes] \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jacs_cache[tapes] \u001b[38;5;241m=\u001b[39m jac\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/jacobian_products.py:452\u001b[0m, in \u001b[0;36mDeviceDerivatives._dev_execute_and_compute_derivatives\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03mConverts tapes to numpy before computing the the results and derivatives on the device.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03mDispatches between the two different device interfaces.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m numpy_tapes, _ \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(tapes)\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_device\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:95\u001b[0m, in \u001b[0;36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     90\u001b[0m         execute_and_derivative_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     91\u001b[0m         executions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     92\u001b[0m         derivatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:60\u001b[0m, in \u001b[0;36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     58\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 60\u001b[0m results, jacs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[38;5;241m0\u001b[39m], jacs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:95\u001b[0m, in \u001b[0;36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     90\u001b[0m         execute_and_derivative_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     91\u001b[0m         executions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     92\u001b[0m         derivatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:60\u001b[0m, in \u001b[0;36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     58\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 60\u001b[0m results, jacs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[38;5;241m0\u001b[39m], jacs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:451\u001b[0m, in \u001b[0;36mLightningBase.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m batch_obs \u001b[38;5;241m=\u001b[39m execution_config\u001b[38;5;241m.\u001b[39mdevice_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_obs)\n\u001b[0;32m--> 451\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_wires_from_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statevector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwire_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wire_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:452\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m batch_obs \u001b[38;5;241m=\u001b[39m execution_config\u001b[38;5;241m.\u001b[39mdevice_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_obs)\n\u001b[1;32m    451\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_wires_from_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statevector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwire_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wire_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m circuit \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:342\u001b[0m, in \u001b[0;36mLightningBase.simulate_and_jacobian\u001b[0;34m(self, circuit, state, batch_obs, wire_map)\u001b[0m\n\u001b[1;32m    340\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulate(circuit, state)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLightningAdjointJacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res, jac\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane_lightning/lightning_qubit/_adjoint_jacobian.py:117\u001b[0m, in \u001b[0;36mLightningAdjointJacobian.calculate_jacobian\u001b[0;34m(self, tape)\u001b[0m\n\u001b[1;32m    114\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(rows))\n\u001b[1;32m    115\u001b[0m red_mat \u001b[38;5;241m=\u001b[39m csr_matrix((data, (rows, cols)), shape\u001b[38;5;241m=\u001b[39m(num_obs, \u001b[38;5;28mlen\u001b[39m(rows)))\n\u001b[0;32m--> 117\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[43mred_mat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m jac \u001b[38;5;241m=\u001b[39m jac\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trainable_params)) \u001b[38;5;28;01mif\u001b[39;00m has_shape0 \u001b[38;5;28;01melse\u001b[39;00m jac\n\u001b[1;32m    119\u001b[0m jac_r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((jac\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_params\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:732\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:624\u001b[0m, in \u001b[0;36m_spbase._matmul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(M, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m N:\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_multivector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_compressed.py:534\u001b[0m, in \u001b[0;36m_cs_matrix._matmul_multivector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    531\u001b[0m M, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape_as_2d\n\u001b[1;32m    532\u001b[0m n_vecs \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# number of column vectors\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_vecs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupcast_char\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# csr_matvecs or csc_matvecs\u001b[39;00m\n\u001b[1;32m    538\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matvecs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculating detailed accuracy metrics...\")\n",
    "metrics  = evaluate_model_per_location_and_hour(\n",
    "    model, test_loader, device, location_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b464440",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_metrics = metrics[\"overall\"]\n",
    "location_metrics = metrics[\"per_location\"]\n",
    "hour_metrics = metrics[\"per_hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPer-location accuracy (averaged over all 72 hours):\")\n",
    "for loc in sorted(location_metrics.keys()):\n",
    "    print(f\"Location {loc}: {location_metrics[loc]['accuracy']:.4f}\")\n",
    "\n",
    "# Plot location accuracy distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist([loc_metrics['accuracy'] for loc_metrics in location_metrics.values()], bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Per-Location Accuracy')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Number of Locations')\n",
    "plt.grid(True)\n",
    "plt.savefig('location_accuracy_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPer-hour accuracy (averaged over all locations):\")\n",
    "for hour_metrics_dict in hour_metrics:\n",
    "    hour = hour_metrics_dict[\"hour\"]\n",
    "    accuracy = hour_metrics_dict[\"accuracy\"]\n",
    "    print(f\"Hour {hour}: {accuracy:.4f}\")\n",
    "\n",
    "# Plot hour accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot([hm[\"hour\"] for hm in hour_metrics], [hm[\"accuracy\"] for hm in hour_metrics], marker='o')\n",
    "plt.title('Accuracy per Forecast Hour')\n",
    "plt.xlabel('Hour Ahead')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.savefig('hour_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After getting metrics\n",
    "print(\"\\nCalculating detailed accuracy metrics...\")\n",
    "metrics = evaluate_model_per_location_and_hour(\n",
    "    model, test_loader, device, location_indices\n",
    ")\n",
    "\n",
    "# Extract metrics\n",
    "overall_metrics = metrics[\"overall\"]\n",
    "location_metrics = metrics[\"per_location\"]\n",
    "hour_metrics = metrics[\"per_hour\"]\n",
    "preds_flat = metrics[\"preds_flat\"]\n",
    "labels_flat = metrics[\"labels_flat\"]\n",
    "\n",
    "# Plot overall confusion matrix\n",
    "print(\"\\nOverall Confusion Matrix:\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(overall_metrics['confusion_matrix'], \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=['Good', 'Poor'],\n",
    "            yticklabels=['Good', 'Poor'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Overall Confusion Matrix')\n",
    "plt.savefig('overall_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print overall metrics\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Accuracy: {overall_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {overall_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {overall_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {overall_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f57d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating example predictions...\")\n",
    "plot_example_predictions(model, X_test, y_test, num_examples=3)\n",
    "\n",
    "print(\"\\nTesting complete. Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
