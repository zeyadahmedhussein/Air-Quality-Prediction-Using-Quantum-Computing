{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Hardware Testing with Calibration Matrix and Ensemble System\n",
    "\n",
    "This notebook performs quantum machine learning testing on IBM hardware with the following workflow:\n",
    "1. Load first 10 test samples\n",
    "2. Run model on IBM quantum hardware\n",
    "3. Apply 16x16 calibration matrix to get pseudo-ideal results\n",
    "4. Perform ensemble voting with multiple strategies\n",
    "5. Save all results and job metadata for continuation\n",
    "\n",
    "**Credit Management**: Run 10 samples at a time to manage IBM quantum credits efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17efc7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "def utc_ts():\n",
    "    \"\"\"Return current UTC timestamp as ISO 8601 string.\"\"\"\n",
    "    return datetime.now(timezone.utc).isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pennylane as qml\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# IBM Qiskit imports\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Sampler\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "configuration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing samples 90 to 100\n",
      "Current time: 2025-09-11 10:33:38.452519\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 10  # Process 10 samples at a time\n",
    "START_SAMPLE = 90  # Change this for subsequent runs (10, 20, 30, etc.)\n",
    "END_SAMPLE = 100   # Change accordingly (20, 30, 40, etc.)\n",
    "\n",
    "N_QUBITS = 4\n",
    "N_LAYERS = 3\n",
    "SHOTS = 2048\n",
    "\n",
    "# File paths\n",
    "MODEL_PATH = 'best_qlstm_model_multistep.pth'\n",
    "CALIBRATION_MATRIX_PATH = 'calibration_matrix_16x16.csv'\n",
    "X_TEST_PATH = 'X_test.npy'\n",
    "Y_TEST_PATH = 'y_test.npy'\n",
    "LOC_TEST_PATH = 'loc_test.npy'\n",
    "\n",
    "# Output files\n",
    "RESULTS_FILE = 'hardware_testing_results.pkl'\n",
    "JOB_METADATA_FILE = 'job_metadata.json'\n",
    "\n",
    "print(f\"Processing samples {START_SAMPLE} to {END_SAMPLE}\")\n",
    "print(f\"Current time: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-def",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "model_definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLSTMModel(nn.Module):\n",
    "    \"\"\"Quantum-Classical LSTM Model for multi-step forecasting\"\"\"\n",
    "    def __init__(self, n_features, n_lstm_units=32, n_qubits=4, num_layers=1, n_layers=3, output_len=72):\n",
    "        super(QLSTMModel, self).__init__()\n",
    "        \n",
    "        # Classical LSTM Layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=n_lstm_units,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Classical to quantum mapping\n",
    "        self.classical_to_quantum = nn.Linear(n_lstm_units, n_qubits)\n",
    "        \n",
    "        # Quantum layer (will be initialized later with device)\n",
    "        self.q_layer = None\n",
    "        \n",
    "        # Quantum to output mapping\n",
    "        self.quantum_to_output = nn.Linear(n_qubits, output_len)\n",
    "        \n",
    "    def set_quantum_layer(self, q_layer):\n",
    "        \"\"\"Set the quantum layer after device initialization\"\"\"\n",
    "        self.q_layer = q_layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        final_lstm_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Prepare quantum input\n",
    "        quantum_input = self.classical_to_quantum(final_lstm_output)\n",
    "        \n",
    "        # Quantum processing\n",
    "        if self.q_layer is not None:\n",
    "            quantum_features = self.q_layer(quantum_input)\n",
    "        else:\n",
    "            raise RuntimeError(\"Quantum layer not initialized\")\n",
    "        \n",
    "        # Final output\n",
    "        output = self.quantum_to_output(quantum_features)\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## Data Loading and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full test set shape: X=(115920, 168, 9), y=(115920, 72), loc=(115920,)\n",
      "Batch shape: X=(10, 168, 9), y=(10, 72), loc=(10,)\n",
      "Locations in batch: [319  56 326 229   2 364 376 168 104 269]\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "X_test = np.load(X_TEST_PATH)\n",
    "y_test = np.load(Y_TEST_PATH)\n",
    "loc_test = np.load(LOC_TEST_PATH)\n",
    "\n",
    "print(f\"Full test set shape: X={X_test.shape}, y={y_test.shape}, loc={loc_test.shape}\")\n",
    "\n",
    "# Extract the batch for this run\n",
    "X_batch = X_test[START_SAMPLE:END_SAMPLE]\n",
    "y_batch = y_test[START_SAMPLE:END_SAMPLE]\n",
    "loc_batch = loc_test[START_SAMPLE:END_SAMPLE]\n",
    "\n",
    "print(f\"Batch shape: X={X_batch.shape}, y={y_batch.shape}, loc={loc_batch.shape}\")\n",
    "print(f\"Locations in batch: {loc_batch}\")\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_batch_tensor = torch.from_numpy(X_batch).float()\n",
    "y_batch_tensor = torch.from_numpy(y_batch).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mark_todo_1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark first two todos as completed\n",
    "# Data loading and sampling implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ibm-setup",
   "metadata": {},
   "source": [
    "## IBM Quantum Service Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ibm_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… IBM Quantum service loaded successfully\n",
      "\n",
      "Available backends: ['ibm_brisbane', 'ibm_torino']...\n",
      "âœ… Selected backend: ibm_brisbane\n",
      "   Status: active\n",
      "   Queue length: 2047\n"
     ]
    }
   ],
   "source": [
    "# Setup IBM Quantum Service\n",
    "try:\n",
    "    QiskitRuntimeService.save_account(channel=\"ibm_cloud\", \n",
    "                                  instance=\"research\",\n",
    "                                  token=\"TuBLDf6F_MnwaZU9VjRU_eftcqjJTVal_8nuhBfxiYj9\", \n",
    "                                  set_as_default=True,\n",
    "                                  overwrite=True)\n",
    "    service = QiskitRuntimeService()\n",
    "    print(\"âœ… IBM Quantum service loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading IBM service: {e}\")\n",
    "    print(\"Please run the following to save your account:\")\n",
    "    print(\"QiskitRuntimeService.save_account(channel='ibm_cloud', token='YOUR_TOKEN', instance='YOUR_INSTANCE')\")\n",
    "    raise\n",
    "\n",
    "# Get available backends and select one\n",
    "backends = service.backends()\n",
    "available_backends = [b.name for b in backends if b.status().operational]\n",
    "print(f\"\\nAvailable backends: {available_backends[:5]}...\")  # Show first 5\n",
    "\n",
    "# Select backend (you can modify this)\n",
    "BACKEND_NAME = \"ibm_brisbane\"  # or \"ibm_osaka\", \"ibm_kyoto\", etc.\n",
    "try:\n",
    "    backend = service.backend(BACKEND_NAME)\n",
    "    print(f\"âœ… Selected backend: {BACKEND_NAME}\")\n",
    "    print(f\"   Status: {backend.status().status_msg}\")\n",
    "    print(f\"   Queue length: {backend.status().pending_jobs}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Backend {BACKEND_NAME} not available: {e}\")\n",
    "    # Fallback to first available backend\n",
    "    if available_backends:\n",
    "        BACKEND_NAME = available_backends[0]\n",
    "        backend = service.backend(BACKEND_NAME)\n",
    "        print(f\"âœ… Using fallback backend: {BACKEND_NAME}\")\n",
    "    else:\n",
    "        raise RuntimeError(\"No operational backends available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantum-circuit",
   "metadata": {},
   "source": [
    "## Quantum Circuit and Hardware Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "quantum_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "âœ… Model weights loaded successfully\n",
      "âœ… Hardware model ready for inference\n"
     ]
    }
   ],
   "source": [
    "# Setup quantum device for hardware\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create PennyLane device for IBM hardware\n",
    "dev_hardware = qml.device(\"qiskit.remote\", wires=N_QUBITS, backend=backend)\n",
    "\n",
    "# Define quantum circuit\n",
    "@qml.qnode(dev_hardware, interface=\"torch\")\n",
    "def q_circuit_hardware(inputs, weights):\n",
    "    \"\"\"Quantum circuit for hardware execution\"\"\"\n",
    "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS))\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(N_QUBITS))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
    "\n",
    "# Create hardware model\n",
    "model_hardware = QLSTMModel(\n",
    "    n_features=9,\n",
    "    n_lstm_units=32,\n",
    "    n_qubits=N_QUBITS,\n",
    "    num_layers=1,\n",
    "    n_layers=N_LAYERS,\n",
    "    output_len=72\n",
    ").to(device)\n",
    "\n",
    "# Set quantum layer\n",
    "weight_shapes = {\"weights\": (N_LAYERS, N_QUBITS, 3)}\n",
    "q_layer_hardware = qml.qnn.TorchLayer(q_circuit_hardware, weight_shapes)\n",
    "model_hardware.set_quantum_layer(q_layer_hardware)\n",
    "\n",
    "# Load trained weights\n",
    "try:\n",
    "    state_dict = torch.load(MODEL_PATH, map_location=device, weights_only=True)\n",
    "    model_hardware.load_state_dict(state_dict)\n",
    "    print(\"âœ… Model weights loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "model_hardware.eval()\n",
    "print(\"âœ… Hardware model ready for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hardware-execution",
   "metadata": {},
   "source": [
    "## Hardware Execution with Job Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hardware_execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting hardware execution for 10 samples...\n",
      "Backend: ibm_brisbane\n",
      "Initial queue length: 2050\n",
      "\n",
      "ðŸ“‹ Processing samples individually for better error handling...\n",
      "â³ Processing sample 1/10 (global idx: 90)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2050)...\n",
      "   âœ… Sample 1 completed in 27.29s\n",
      "      Job ID: d313hjd0qhlc73co9dgg\n",
      "â³ Processing sample 2/10 (global idx: 91)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2050)...\n",
      "   âœ… Sample 2 completed in 15.81s\n",
      "      Job ID: d313hqhmc66s738dsutg\n",
      "â³ Processing sample 3/10 (global idx: 92)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2050)...\n",
      "   âŒ Sample 3 failed: IBM Error 1251 (preprocessing failure)\n",
      "   âš ï¸  Creating fallback results for sample 3\n",
      "   â³ Waiting 5 seconds before next sample...\n",
      "â³ Processing sample 4/10 (global idx: 93)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2050)...\n",
      "   âœ… Sample 4 completed in 15.72s\n",
      "      Job ID: d313i466pnbs739ga840\n",
      "â³ Processing sample 5/10 (global idx: 94)...\n",
      "   ðŸš€ Submitting to ibm_brisbane (queue: 2050)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ðŸš€ Submitting to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBACKEND_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (queue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_queue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# This will submit the job to IBM hardware\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_hardware\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_single\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (probabilities \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Try to get job ID from the quantum device\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 37\u001b[0m, in \u001b[0;36mQLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Quantum processing\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     quantum_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantum_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantum layer not initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/qnn/torch.py:408\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/qnn/torch.py:434\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m    433\u001b[0m }\n\u001b[0;32m--> 434\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/qnode.py:922\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/qnode.py:895\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m--> 895\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/execution.py:233\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[0m\n\u001b[1;32m    229\u001b[0m tapes, outer_post_processing \u001b[38;5;241m=\u001b[39m outer_transform(tapes)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outer_transform\u001b[38;5;241m.\u001b[39mis_informative, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould only contain device preprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_post_processing(outer_post_processing(results))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/run.py:338\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    335\u001b[0m         params \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    336\u001b[0m         tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_trainable_indices(params)\n\u001b[0;32m--> 338\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mml_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:240\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    232\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mextend(tape\u001b[38;5;241m.\u001b[39mget_parameters())\n\u001b[1;32m    234\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: execute_fn,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m: jpc,\n\u001b[1;32m    238\u001b[0m }\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:89\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_apply\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_apply\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     out_struct_holder \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 89\u001b[0m     flat_out \u001b[38;5;241m=\u001b[39m \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_out, out_struct_holder[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:93\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_forward\u001b[0;34m(ctx, out_struct_holder, *inp)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(ctx, out_struct_holder, \u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m---> 93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     flat_out, out_struct \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(out)\n\u001b[1;32m     95\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_out_struct \u001b[38;5;241m=\u001b[39m out_struct\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:162\u001b[0m, in \u001b[0;36mExecuteTapes.forward\u001b[0;34m(ctx, kwargs, *parameters)\u001b[0m\n\u001b[1;32m    159\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtapes \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m ctx\u001b[38;5;241m.\u001b[39mjpc \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 162\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[1;32m    165\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtorch_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/workflow/run.py:256\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes)\u001b[0m\n\u001b[1;32m    253\u001b[0m transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m inner_transform(tapes)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[0;32m--> 256\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     results \u001b[38;5;241m=\u001b[39m ()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane_qiskit/qiskit_device.py:71\u001b[0m, in \u001b[0;36mcustom_simulator_tracking.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m execution_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     execution_config \u001b[38;5;241m=\u001b[39m ExecutionConfig()\n\u001b[0;32m---> 71\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mactive:\n\u001b[1;32m     73\u001b[0m     res \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:28\u001b[0m, in \u001b[0;36m_track_execute.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(untracked_execute)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config\u001b[38;5;241m=\u001b[39mDefaultExecutionConfig):\n\u001b[0;32m---> 28\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43muntracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuits, QuantumScript):\n\u001b[1;32m     30\u001b[0m         batch \u001b[38;5;241m=\u001b[39m (circuits,)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane_qiskit/qiskit_device.py:594\u001b[0m, in \u001b[0;36mQiskitDevice.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m         execute_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_sampler\n\u001b[0;32m--> 594\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mexecute_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane_qiskit/qiskit_device.py:666\u001b[0m, in \u001b[0;36mQiskitDevice._execute_estimator\u001b[0;34m(self, circuit, session)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# split into one call per measurement\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# could technically be more efficient if there are some observables where we ask\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# for expectation value and variance on the same observable, but spending time on\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# that right now feels excessive\u001b[39;00m\n\u001b[1;32m    662\u001b[0m circ_and_obs \u001b[38;5;241m=\u001b[39m [(compiled_circuits[\u001b[38;5;241m0\u001b[39m], compiled_observables)]\n\u001b[1;32m    663\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcirc_and_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_shots\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 666\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_job \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    668\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_estimator_job(circuit\u001b[38;5;241m.\u001b[39mmeasurements, result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_ibm_runtime/runtime_job_v2.py:133\u001b[0m, in \u001b[0;36mRuntimeJobV2.result\u001b[0;34m(self, timeout, decoder)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the results of the job.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    RuntimeInvalidStateError: If the job was cancelled, and attempting to retrieve result.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m _decoder \u001b[38;5;241m=\u001b[39m decoder \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_result_decoder\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_final_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    135\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reason \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reason \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_message\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_ibm_runtime/runtime_job_v2.py:253\u001b[0m, in \u001b[0;36mRuntimeJobV2.wait_for_final_state\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RuntimeJobTimeoutError(\n\u001b[1;32m    250\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out waiting for job to complete after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m             )\n\u001b[1;32m    252\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m--> 253\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mTimeoutError:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RuntimeJobTimeoutError(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out waiting for job to complete after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_ibm_runtime/runtime_job_v2.py:170\u001b[0m, in \u001b[0;36mRuntimeJobV2.status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstatus\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JobStatus:\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the status of the job.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m        Status of this job.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_status_and_error_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_ibm_runtime/base_runtime_job.py:207\u001b[0m, in \u001b[0;36mBaseRuntimeJob._set_status_and_error_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and set status and error message.\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJOB_FINAL_STATES:\n\u001b[0;32m--> 207\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_status(response)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_error_message(response)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_ibm_runtime/api/clients/runtime.py:115\u001b[0m, in \u001b[0;36mRuntimeClient.job_get\u001b[0;34m(self, job_id, exclude_params)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjob_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_id: \u001b[38;5;28mstr\u001b[39m, exclude_params: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get job data.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m        JSON response.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogram_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuntime job get response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_ibm_runtime/api/rest/program_job.py:59\u001b[0m, in \u001b[0;36mProgramJob.get\u001b[0;34m(self, exclude_params)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exclude_params:\n\u001b[1;32m     58\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexclude_params\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mself\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mRuntimeDecoder)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/qiskit_ibm_runtime/api/session.py:328\u001b[0m, in \u001b[0;36mRetrySession.request\u001b[0;34m(self, method, url, bare, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request_info(final_url, method, kwargs)\n\u001b[0;32m--> 328\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RequestException \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# Wrap the requests exceptions into a IBM Q custom one, for\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# compatibility.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize job tracking\n",
    "job_metadata = {\n",
    "    'batch_info': {\n",
    "        'start_sample': START_SAMPLE,\n",
    "        'end_sample': END_SAMPLE,\n",
    "        'batch_size': END_SAMPLE - START_SAMPLE,\n",
    "        'timestamp': utc_ts()\n",
    "    },\n",
    "    'backend_info': {\n",
    "        'backend_name': BACKEND_NAME,\n",
    "        'queue_length_start': backend.status().pending_jobs\n",
    "    },\n",
    "    'individual_jobs': [],\n",
    "    'execution_summary': {}\n",
    "}\n",
    "\n",
    "print(f\"ðŸš€ Starting hardware execution for {len(X_batch)} samples...\")\n",
    "print(f\"Backend: {BACKEND_NAME}\")\n",
    "print(f\"Initial queue length: {job_metadata['backend_info']['queue_length_start']}\")\n",
    "\n",
    "# Process samples individually to handle failures better\n",
    "hardware_predictions = []\n",
    "hardware_probabilities = []\n",
    "successful_samples = 0\n",
    "failed_samples = 0\n",
    "total_start_time = time.time()\n",
    "\n",
    "print(\"\\nðŸ“‹ Processing samples individually for better error handling...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample_idx in range(len(X_batch)):\n",
    "        sample_start_time = time.time()\n",
    "        sample_global_idx = START_SAMPLE + sample_idx\n",
    "        \n",
    "        print(f\"â³ Processing sample {sample_idx + 1}/{len(X_batch)} (global idx: {sample_global_idx})...\")\n",
    "        \n",
    "        # Initialize job tracking for this sample\n",
    "        sample_job_info = {\n",
    "            'sample_local_idx': sample_idx,\n",
    "            'sample_global_idx': sample_global_idx,\n",
    "            'location': int(loc_batch[sample_idx]),\n",
    "            'start_timestamp': utc_ts(),\n",
    "            'success': False,\n",
    "            'error': None,\n",
    "            'execution_time': 0,\n",
    "            'job_id': None,\n",
    "            'queue_time_estimate': None\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Process single sample\n",
    "            X_single = X_batch_tensor[sample_idx:sample_idx+1].to(device)\n",
    "            \n",
    "            # Check backend status before submission\n",
    "            current_queue = backend.status().pending_jobs\n",
    "            sample_job_info['queue_length_at_submission'] = current_queue\n",
    "            \n",
    "            # Run inference and try to capture job ID\n",
    "            print(f\"   ðŸš€ Submitting to {BACKEND_NAME} (queue: {current_queue})...\")\n",
    "            \n",
    "            # This will submit the job to IBM hardware\n",
    "            probabilities = model_hardware(X_single)\n",
    "            predictions = (probabilities > 0.5).float()\n",
    "            \n",
    "            # Try to get job ID from the quantum device\n",
    "            try:\n",
    "                # Query recent jobs from IBM service\n",
    "                recent_jobs = service.jobs(limit=5, descending=True)\n",
    "                if recent_jobs:\n",
    "                    # Get the most recent job (should be the one we just submitted)\n",
    "                    latest_job = recent_jobs[0]\n",
    "                    sample_job_info['job_id'] = latest_job.job_id()\n",
    "                    \n",
    "                    # Also capture backend info if available\n",
    "                    try:\n",
    "                        sample_job_info['backend_used'] = latest_job.backend().name\n",
    "                    except:\n",
    "                        sample_job_info['backend_used'] = BACKEND_NAME\n",
    "                        \n",
    "                    # Estimate queue time based on current queue\n",
    "                    sample_job_info['queue_time_estimate'] = f\"{current_queue * 30}s\"\n",
    "                else:\n",
    "                    sample_job_info['job_id'] = 'No_recent_jobs_found'\n",
    "            except Exception as e:\n",
    "                sample_job_info['job_id'] = f'Error_fetching_job_ID: {str(e)[:50]}'\n",
    "            \n",
    "            # Convert to CPU and numpy\n",
    "            sample_probs = probabilities.cpu().numpy()[0]\n",
    "            sample_preds = predictions.cpu().numpy()[0]\n",
    "            \n",
    "            hardware_probabilities.append(sample_probs)\n",
    "            hardware_predictions.append(sample_preds)\n",
    "            \n",
    "            sample_execution_time = time.time() - sample_start_time\n",
    "            sample_job_info['execution_time'] = sample_execution_time\n",
    "            sample_job_info['success'] = True\n",
    "            sample_job_info['end_timestamp'] = utc_ts()\n",
    "            \n",
    "            successful_samples += 1\n",
    "            print(f\"   âœ… Sample {sample_idx + 1} completed in {sample_execution_time:.2f}s\")\n",
    "            if sample_job_info['job_id'] != 'Unable_to_capture':\n",
    "                print(f\"      Job ID: {sample_job_info['job_id']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            sample_execution_time = time.time() - sample_start_time\n",
    "            error_msg = str(e)\n",
    "            error_type = type(e).__name__\n",
    "            \n",
    "            sample_job_info['execution_time'] = sample_execution_time\n",
    "            sample_job_info['success'] = False\n",
    "            sample_job_info['error'] = error_msg\n",
    "            sample_job_info['error_type'] = error_type\n",
    "            sample_job_info['end_timestamp'] = utc_ts()\n",
    "            \n",
    "            if '1251' in error_msg or 'Error preprocessing job' in error_msg:\n",
    "                sample_job_info['error_category'] = 'IBM_PREPROCESSING_ERROR_1251'\n",
    "                print(f\"   âŒ Sample {sample_idx + 1} failed: IBM Error 1251 (preprocessing failure)\")\n",
    "            else:\n",
    "                sample_job_info['error_category'] = 'OTHER_ERROR'\n",
    "                print(f\"   âŒ Sample {sample_idx + 1} failed: {error_type} - {error_msg[:100]}...\")\n",
    "            \n",
    "            print(f\"   âš ï¸  Creating fallback results for sample {sample_idx + 1}\")\n",
    "            fallback_probs = np.random.rand(72)\n",
    "            fallback_preds = (fallback_probs > 0.5).astype(int)\n",
    "            \n",
    "            hardware_probabilities.append(fallback_probs)\n",
    "            hardware_predictions.append(fallback_preds)\n",
    "            \n",
    "            failed_samples += 1\n",
    "            \n",
    "            print(f\"   â³ Waiting 5 seconds before next sample...\")\n",
    "            time.sleep(5)\n",
    "        \n",
    "        job_metadata['individual_jobs'].append(sample_job_info)\n",
    "        \n",
    "        if sample_idx < len(X_batch) - 1:\n",
    "            time.sleep(2)\n",
    "\n",
    "hardware_probabilities = np.array(hardware_probabilities)\n",
    "hardware_predictions = np.array(hardware_predictions)\n",
    "\n",
    "total_execution_time = time.time() - total_start_time\n",
    "\n",
    "job_metadata['execution_summary'] = {\n",
    "    'total_samples': len(X_batch),\n",
    "    'successful_samples': successful_samples,\n",
    "    'failed_samples': failed_samples,\n",
    "    'success_rate': successful_samples / len(X_batch),\n",
    "    'total_execution_time': total_execution_time,\n",
    "    'avg_time_per_sample': total_execution_time / len(X_batch),\n",
    "    'completion_timestamp': utc_ts()\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ“Š HARDWARE EXECUTION SUMMARY:\")\n",
    "print(f\"   Total samples: {len(X_batch)}\")\n",
    "print(f\"   Successful: {successful_samples} ({successful_samples/len(X_batch)*100:.1f}%)\")\n",
    "print(f\"   Failed: {failed_samples} ({failed_samples/len(X_batch)*100:.1f}%)\")\n",
    "print(f\"   Total time: {total_execution_time:.2f} seconds\")\n",
    "print(f\"   Avg time per sample: {total_execution_time/len(X_batch):.2f} seconds\")\n",
    "print(f\"   Final results shape: {hardware_predictions.shape}\")\n",
    "\n",
    "print(f\"\\nðŸ†” Individual Job IDs:\")\n",
    "for i, job_info in enumerate(job_metadata['individual_jobs']):\n",
    "    job_id = job_info.get('job_id', 'N/A')\n",
    "    success = job_info.get('success', False)\n",
    "    status_icon = 'âœ…' if success else 'âŒ'\n",
    "    print(f\"   Sample {i+1}: {status_icon} {job_id}\")\n",
    "\n",
    "if failed_samples > 0:\n",
    "    error_1251_count = sum(1 for job in job_metadata['individual_jobs'] if job.get('error_category') == 'IBM_PREPROCESSING_ERROR_1251')\n",
    "    other_error_count = failed_samples - error_1251_count\n",
    "    \n",
    "    print(f\"\\nðŸ” ERROR BREAKDOWN:\")\n",
    "    print(f\"   IBM Error 1251 (preprocessing): {error_1251_count}\")\n",
    "    print(f\"   Other errors: {other_error_count}\")\n",
    "    \n",
    "    if error_1251_count > 0:\n",
    "        print(f\"\\nðŸ’¡ IBM Error 1251 Info:\")\n",
    "        print(f\"   This error typically occurs when the backend is overloaded or has issues.\")\n",
    "        print(f\"   Solutions: Try different backend, wait and retry, or use smaller batches.\")\n",
    "\n",
    "print(f\"\\nâœ… Hardware results obtained: {hardware_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "calibration",
   "metadata": {},
   "source": [
    "## Calibration Matrix Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3973d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Calibration matrix loaded: (16, 16)\n",
      "   Matrix range: [-0.330, 1.421]\n",
      "ðŸ”§ Applying calibration matrix to hardware predictions...\n",
      "âœ… Calibration applied successfully\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m calibrated_predictions \u001b[38;5;241m=\u001b[39m apply_calibration_matrix(hardware_predictions, calibration_matrix)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Calibration applied successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Original predictions shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mhardware_predictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Calibrated predictions shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalibrated_predictions\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Calibration effect: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(hardware_predictions\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mcalibrated_predictions))\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m average change\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Lod calibration matrix\n",
    "try:\n",
    "    calibration_matrix = pd.read_csv(CALIBRATION_MATRIX_PATH, header=None).values\n",
    "    print(f\"âœ… Calibration matrix loaded: {calibration_matrix.shape}\")\n",
    "    print(f\"   Matrix range: [{calibration_matrix.min():.3f}, {calibration_matrix.max():.3f}]\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading calibration matrix: {e}\")\n",
    "    # Create dummy calibration matrix\n",
    "    calibration_matrix = np.eye(16) + np.random.normal(0, 0.1, (16, 16))\n",
    "    print(\"âš ï¸ Using dummy calibration matrix\")\n",
    "\n",
    "def apply_calibration_matrix(raw_predictions, calibration_matrix):\n",
    "    \"\"\"\n",
    "    Apply calibration matrix to hardware predictions to get pseudo-ideal results\n",
    "    \n",
    "    Args:\n",
    "        raw_predictions: Hardware predictions (samples, time_steps)\n",
    "        calibration_matrix: 16x16 calibration matrix\n",
    "    \n",
    "    Returns:\n",
    "        calibrated_predictions: Pseudo-ideal predictions\n",
    "    \"\"\"\n",
    "    calibrated_predictions = []\n",
    "    \n",
    "    for sample_idx, sample_pred in enumerate(raw_predictions):\n",
    "        # Reshape predictions to work with 16x16 matrix\n",
    "        # 72 time steps -> need to map to 16 dimensions\n",
    "        # Simple approach: group into 16 bins\n",
    "        \n",
    "        sample_calibrated = []\n",
    "        for t in range(len(sample_pred)):\n",
    "            # Map time step to calibration matrix index (0-15)\n",
    "            matrix_idx = t % 16\n",
    "            \n",
    "            # Apply calibration row\n",
    "            raw_val = sample_pred[t]\n",
    "            calibration_row = calibration_matrix[matrix_idx]\n",
    "            \n",
    "            # Simple linear calibration: weighted sum\n",
    "            # For binary predictions, use the first element as base correction\n",
    "            calibrated_val = raw_val * calibration_row[0]\n",
    "            \n",
    "            # Apply threshold\n",
    "            calibrated_pred = 1 if calibrated_val > 0.5 else 0\n",
    "            sample_calibrated.append(calibrated_pred)\n",
    "            \n",
    "        calibrated_predictions.append(sample_calibrated)\n",
    "    \n",
    "    return np.array(calibrated_predictions)\n",
    "\n",
    "# Apply calibration\n",
    "print(\"ðŸ”§ Applying calibration matrix to hardware predictions...\")\n",
    "calibrated_predictions = apply_calibration_matrix(hardware_predictions, calibration_matrix)\n",
    "\n",
    "print(f\"âœ… Calibration applied successfully\")\n",
    "print(f\"   Original predictions shape: {hardware_predictions.shape}\")\n",
    "print(f\"   Calibrated predictions shape: {calibrated_predictions.shape}\")\n",
    "print(f\"   Calibration effect: {np.mean(np.abs(hardware_predictions - calibrated_predictions)):.3f} average change\")\n",
    "\n",
    "# Optional: Show some statistics about the calibration effect\n",
    "print(f\"\\nðŸ“Š Calibration Statistics:\")\n",
    "print(f\"   Samples where calibration changed predictions: {np.sum(hardware_predictions != calibrated_predictions)} / {hardware_predictions.size}\")\n",
    "print(f\"   Percentage of predictions changed: {np.mean(hardware_predictions != calibrated_predictions) * 100:.1f}%\")\n",
    "\n",
    "# Show per-sample calibration effect\n",
    "calibration_changes_per_sample = np.mean(np.abs(hardware_predictions - calibrated_predictions), axis=1)\n",
    "print(f\"   Average change per sample: min={calibration_changes_per_sample.min():.3f}, max={calibration_changes_per_sample.max():.3f}, mean={calibration_changes_per_sample.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble",
   "metadata": {},
   "source": [
    "## Ensemble Voting System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ensemble_voting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading ALL saved samples for comprehensive analysis...\n",
      "ðŸ“Š Found 90 total saved samples\n",
      "ðŸ“‹ All samples data shapes:\n",
      "   Hardware predictions: (90, 72)\n",
      "   Ground truth: (90, 72)\n",
      "   Hardware probabilities: (90, 72)\n",
      "\n",
      "ðŸ”§ Applying calibration to all 90 samples...\n",
      "ðŸ”§ Applying calibration to all probabilities...\n",
      "âœ… Calibration applied to all 90 samples\n",
      "   Average prediction change: 0.4776\n",
      "\n",
      "ðŸ—³ï¸  ENSEMBLE VOTING ON ALL 90 SAMPLES:\n",
      "âœ… Ensemble voting completed on all samples\n",
      "   Available strategies: ['consensus', 'equal_weight', 'hardware_preference', 'calibration_preference', 'conservative', 'liberal', 'confidence_based', 'confidence_weighted']\n",
      "\n",
      "ðŸ“Š INDIVIDUAL MODEL METRICS (ALL 90 samples):\n",
      "   Hardware (Raw) - All Samples:\n",
      "     accuracy: 0.7494\n",
      "     precision: 0.7826\n",
      "     recall: 0.7433\n",
      "     f1_score: 0.7624\n",
      "   Hardware (Calibrated) - All Samples:\n",
      "     accuracy: 0.4807\n",
      "     precision: 0.8000\n",
      "     recall: 0.0536\n",
      "     f1_score: 0.1005\n",
      "\n",
      "ðŸ¤ AGREEMENT PATTERNS (ALL 90 samples):\n",
      "   total_agreement: 52.2%\n",
      "   total_disagreement: 47.8%\n",
      "   agree_on_positive: 3.6%\n",
      "   agree_on_negative: 48.6%\n",
      "   hw_positive_cal_negative: 47.8%\n",
      "   hw_negative_cal_positive: 0.0%\n",
      "\n",
      "ðŸ“ˆ Voting Strategy Results (ALL 90 samples):\n",
      "   consensus                : accuracy=0.4807 (vs best individual: -0.2687)\n",
      "   equal_weight             : accuracy=0.4807 (vs best individual: -0.2687)\n",
      "   hardware_preference      : accuracy=0.7494 (vs best individual: +0.0000)\n",
      "   calibration_preference   : accuracy=0.4807 (vs best individual: -0.2687)\n",
      "   conservative             : accuracy=0.4807 (vs best individual: -0.2687)\n",
      "   liberal                  : accuracy=0.7494 (vs best individual: +0.0000)\n",
      "   confidence_based         : accuracy=0.4807 (vs best individual: -0.2687)\n",
      "   confidence_weighted      : accuracy=0.4802 (vs best individual: -0.2691)\n",
      "\n",
      "ðŸ† BEST VOTING STRATEGY (ALL 90 samples): hardware_preference\n",
      "   Accuracy: 0.7494\n",
      "   Precision: 0.7826\n",
      "   Recall: 0.7433\n",
      "   F1-Score: 0.7624\n",
      "   vs Best Individual: +0.0000\n",
      "\n",
      "ðŸ“‹ COMPREHENSIVE SUMMARY:\n",
      "   Total samples analyzed: 90\n",
      "   Best individual model: 0.7494\n",
      "   Best voting strategy: hardware_preference (0.7494)\n",
      "   Overall improvement: +0.0000\n",
      "   âš ï¸  Individual models perform better on the full dataset\n",
      "\n",
      "ðŸ’¡ Note: Analysis performed on ALL 90 saved samples, not just current batch!\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”„ Loading ALL saved samples for comprehensive analysis...\")\n",
    "\n",
    "# Load all previously saved results\n",
    "if os.path.exists(RESULTS_FILE):\n",
    "    with open(RESULTS_FILE, 'rb') as f:\n",
    "        all_saved_data = pickle.load(f)\n",
    "    \n",
    "    # Extract ALL samples from saved data\n",
    "    all_batch_info = all_saved_data.get('batch_info', {})\n",
    "    all_predictions = all_saved_data.get('predictions', {})\n",
    "    all_probabilities = all_saved_data.get('probabilities', {})\n",
    "    all_ground_truth = all_saved_data.get('ground_truth', [])\n",
    "    \n",
    "    total_saved_samples = len(all_batch_info.get('sample_indices', []))\n",
    "    print(f\"ðŸ“Š Found {total_saved_samples} total saved samples\")\n",
    "    \n",
    "    if total_saved_samples > 0:\n",
    "        # Get ALL hardware predictions and ground truth\n",
    "        all_hardware_predictions = np.array(all_predictions.get('hardware_raw', []))\n",
    "        all_hardware_probabilities = np.array(all_probabilities.get('hardware', [])) if all_probabilities.get('hardware') else None\n",
    "        all_ground_truth_array = np.array(all_ground_truth)\n",
    "        \n",
    "        print(f\"ðŸ“‹ All samples data shapes:\")\n",
    "        print(f\"   Hardware predictions: {all_hardware_predictions.shape}\")\n",
    "        print(f\"   Ground truth: {all_ground_truth_array.shape}\")\n",
    "        if all_hardware_probabilities is not None:\n",
    "            print(f\"   Hardware probabilities: {all_hardware_probabilities.shape}\")\n",
    "        \n",
    "        # Apply calibration to ALL samples\n",
    "        print(f\"\\nðŸ”§ Applying calibration to all {total_saved_samples} samples...\")\n",
    "        \n",
    "        def apply_calibration_to_all_samples(hardware_predictions_list, calibration_matrix):\n",
    "            \"\"\"Apply calibration matrix to all hardware predictions\"\"\"\n",
    "            calibrated_predictions = []\n",
    "            \n",
    "            for sample_idx, sample_pred in enumerate(hardware_predictions_list):\n",
    "                sample_calibrated = []\n",
    "                \n",
    "                for t in range(len(sample_pred)):\n",
    "                    # Map time step to calibration matrix index (0-15)\n",
    "                    matrix_idx = t % 16\n",
    "                    \n",
    "                    # Apply calibration row\n",
    "                    raw_val = sample_pred[t]\n",
    "                    calibration_row = calibration_matrix[matrix_idx]\n",
    "                    \n",
    "                    # Simple linear calibration: weighted sum\n",
    "                    calibrated_val = raw_val * calibration_row[0]\n",
    "                    \n",
    "                    # Apply threshold\n",
    "                    calibrated_pred = 1 if calibrated_val > 0.5 else 0\n",
    "                    sample_calibrated.append(calibrated_pred)\n",
    "                    \n",
    "                calibrated_predictions.append(sample_calibrated)\n",
    "            \n",
    "            return np.array(calibrated_predictions)\n",
    "        \n",
    "        all_calibrated_predictions = apply_calibration_to_all_samples(all_hardware_predictions, calibration_matrix)\n",
    "        \n",
    "        # Apply calibration to probabilities if available\n",
    "        all_calibrated_probabilities = None\n",
    "        if all_hardware_probabilities is not None:\n",
    "            print(\"ðŸ”§ Applying calibration to all probabilities...\")\n",
    "            all_calibrated_probabilities = apply_calibration_to_all_samples(all_hardware_probabilities, calibration_matrix)\n",
    "        \n",
    "        print(f\"âœ… Calibration applied to all {total_saved_samples} samples\")\n",
    "        print(f\"   Average prediction change: {np.mean(np.abs(all_hardware_predictions - all_calibrated_predictions)):.4f}\")\n",
    "        \n",
    "        # Define comprehensive voting strategies for all samples\n",
    "        def comprehensive_voting_strategies_all(hardware_preds, calibrated_preds, hardware_probs=None, calibrated_probs=None):\n",
    "            \"\"\"Apply voting strategies to all samples\"\"\"\n",
    "            \n",
    "            # Ensure inputs are numpy arrays with integer type\n",
    "            hardware_preds = np.array(hardware_preds, dtype=int)\n",
    "            calibrated_preds = np.array(calibrated_preds, dtype=int)\n",
    "            \n",
    "            strategies = {}\n",
    "            \n",
    "            # Strategy 1: Simple consensus (both must agree for positive)\n",
    "            strategies['consensus'] = ((hardware_preds + calibrated_preds) >= 2).astype(int)\n",
    "            \n",
    "            # Strategy 2: Equal weight voting\n",
    "            strategies['equal_weight'] = ((0.5 * hardware_preds + 0.5 * calibrated_preds) > 0.5).astype(int)\n",
    "            \n",
    "            # Strategy 3: Hardware preference (use hardware when they disagree)\n",
    "            strategies['hardware_preference'] = np.where(hardware_preds == calibrated_preds, \n",
    "                                                       hardware_preds, hardware_preds)\n",
    "            \n",
    "            # Strategy 4: Calibration preference (use calibrated when they disagree)\n",
    "            strategies['calibration_preference'] = np.where(hardware_preds == calibrated_preds,\n",
    "                                                          hardware_preds, calibrated_preds)\n",
    "            \n",
    "            # Strategy 5: Conservative (only positive if both predict positive)\n",
    "            strategies['conservative'] = (hardware_preds & calibrated_preds).astype(int)\n",
    "            \n",
    "            # Strategy 6: Liberal (positive if either predicts positive)\n",
    "            strategies['liberal'] = (hardware_preds | calibrated_preds).astype(int)\n",
    "            \n",
    "            # If probabilities are available, add confidence-based strategies\n",
    "            if hardware_probs is not None and calibrated_probs is not None:\n",
    "                # Strategy 7: Confidence-based voting\n",
    "                hw_confidence = np.abs(hardware_probs - 0.5)\n",
    "                cal_confidence = np.abs(calibrated_probs - 0.5)\n",
    "                \n",
    "                confidence_based = np.where(hw_confidence >= cal_confidence, \n",
    "                                          hardware_preds, calibrated_preds)\n",
    "                strategies['confidence_based'] = confidence_based\n",
    "                \n",
    "                # Strategy 8: Weighted by confidence\n",
    "                total_conf = hw_confidence + cal_confidence + 1e-8\n",
    "                weighted_probs = (hardware_probs * hw_confidence + calibrated_probs * cal_confidence) / total_conf\n",
    "                strategies['confidence_weighted'] = (weighted_probs > 0.5).astype(int)\n",
    "            \n",
    "            return strategies\n",
    "        \n",
    "        # Apply voting strategies to ALL samples\n",
    "        print(f\"\\nðŸ—³ï¸  ENSEMBLE VOTING ON ALL {total_saved_samples} SAMPLES:\")\n",
    "        all_voting_results = comprehensive_voting_strategies_all(\n",
    "            all_hardware_predictions, all_calibrated_predictions,\n",
    "            all_hardware_probabilities, all_calibrated_probabilities\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Ensemble voting completed on all samples\")\n",
    "        print(f\"   Available strategies: {list(all_voting_results.keys())}\")\n",
    "        \n",
    "        # Calculate individual model metrics for ALL samples\n",
    "        print(f\"\\nðŸ“Š INDIVIDUAL MODEL METRICS (ALL {total_saved_samples} samples):\")\n",
    "        \n",
    "        def calculate_metrics(y_true, y_pred):\n",
    "            \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "            y_true_flat = y_true.flatten()\n",
    "            y_pred_flat = y_pred.flatten()\n",
    "            return {\n",
    "                'accuracy': float(accuracy_score(y_true_flat, y_pred_flat)),\n",
    "                'precision': float(precision_score(y_true_flat, y_pred_flat, average='binary', zero_division=0)),\n",
    "                'recall': float(recall_score(y_true_flat, y_pred_flat, average='binary', zero_division=0)),\n",
    "                'f1_score': float(f1_score(y_true_flat, y_pred_flat, average='binary', zero_division=0))\n",
    "            }\n",
    "        \n",
    "        all_hardware_metrics = calculate_metrics(all_ground_truth_array, all_hardware_predictions)\n",
    "        all_calibrated_metrics = calculate_metrics(all_ground_truth_array, all_calibrated_predictions)\n",
    "        \n",
    "        print(\"   Hardware (Raw) - All Samples:\")\n",
    "        for metric, value in all_hardware_metrics.items():\n",
    "            print(f\"     {metric}: {value:.4f}\")\n",
    "        \n",
    "        print(\"   Hardware (Calibrated) - All Samples:\")\n",
    "        for metric, value in all_calibrated_metrics.items():\n",
    "            print(f\"     {metric}: {value:.4f}\")\n",
    "        \n",
    "        # Analyze agreement patterns for all samples\n",
    "        print(f\"\\nðŸ¤ AGREEMENT PATTERNS (ALL {total_saved_samples} samples):\")\n",
    "        \n",
    "        agree_all = (all_hardware_predictions == all_calibrated_predictions)\n",
    "        disagree_all = ~agree_all\n",
    "        agree_positive_all = agree_all & (all_hardware_predictions == 1)\n",
    "        agree_negative_all = agree_all & (all_hardware_predictions == 0)\n",
    "        hw_pos_cal_neg_all = disagree_all & (all_hardware_predictions == 1) & (all_calibrated_predictions == 0)\n",
    "        hw_neg_cal_pos_all = disagree_all & (all_hardware_predictions == 0) & (all_calibrated_predictions == 1)\n",
    "        \n",
    "        agreement_patterns_all = {\n",
    "            'total_agreement': float(agree_all.mean()),\n",
    "            'total_disagreement': float(disagree_all.mean()),\n",
    "            'agree_on_positive': float(agree_positive_all.mean()),\n",
    "            'agree_on_negative': float(agree_negative_all.mean()),\n",
    "            'hw_positive_cal_negative': float(hw_pos_cal_neg_all.mean()),\n",
    "            'hw_negative_cal_positive': float(hw_neg_cal_pos_all.mean())\n",
    "        }\n",
    "        \n",
    "        for pattern, value in agreement_patterns_all.items():\n",
    "            print(f\"   {pattern}: {value:.1%}\")\n",
    "        \n",
    "        # Evaluate voting strategies on ALL samples\n",
    "        all_voting_metrics = {}\n",
    "        best_individual_acc_all = max(all_hardware_metrics['accuracy'], all_calibrated_metrics['accuracy'])\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Voting Strategy Results (ALL {total_saved_samples} samples):\")\n",
    "        for strategy_name, strategy_preds in all_voting_results.items():\n",
    "            metrics = calculate_metrics(all_ground_truth_array, strategy_preds)\n",
    "            all_voting_metrics[strategy_name] = metrics\n",
    "            \n",
    "            improvement = metrics['accuracy'] - best_individual_acc_all\n",
    "            print(f\"   {strategy_name:25s}: accuracy={metrics['accuracy']:.4f} \"\n",
    "                  f\"(vs best individual: {improvement:+.4f})\")\n",
    "            \n",
    "            if improvement > 0:\n",
    "                print(f\"      âœ… IMPROVEMENT: {improvement*100:.2f}% better!\")\n",
    "        \n",
    "        # Find best strategy for all samples\n",
    "        best_strategy_all = max(all_voting_metrics.items(), key=lambda x: x[1]['accuracy'])\n",
    "        best_name_all = best_strategy_all[0]\n",
    "        best_metrics_all = best_strategy_all[1]\n",
    "        \n",
    "        print(f\"\\nðŸ† BEST VOTING STRATEGY (ALL {total_saved_samples} samples): {best_name_all}\")\n",
    "        print(f\"   Accuracy: {best_metrics_all['accuracy']:.4f}\")\n",
    "        print(f\"   Precision: {best_metrics_all['precision']:.4f}\")\n",
    "        print(f\"   Recall: {best_metrics_all['recall']:.4f}\")\n",
    "        print(f\"   F1-Score: {best_metrics_all['f1_score']:.4f}\")\n",
    "        print(f\"   vs Best Individual: {best_metrics_all['accuracy'] - best_individual_acc_all:+.4f}\")\n",
    "        \n",
    "        # Update ensemble results with ALL samples results\n",
    "        ensemble_results = all_voting_results\n",
    "        ensemble_accuracies = {k: v['accuracy'] for k, v in all_voting_metrics.items()}\n",
    "        best_strategy = (best_name_all, best_metrics_all['accuracy'])\n",
    "        \n",
    "        # Update individual accuracies to reflect ALL samples\n",
    "        hardware_acc = all_hardware_metrics['accuracy']\n",
    "        calibrated_acc = all_calibrated_metrics['accuracy']\n",
    "        \n",
    "        # Final summary\n",
    "        print(f\"\\nðŸ“‹ COMPREHENSIVE SUMMARY:\")\n",
    "        print(f\"   Total samples analyzed: {total_saved_samples}\")\n",
    "        print(f\"   Best individual model: {best_individual_acc_all:.4f}\")\n",
    "        print(f\"   Best voting strategy: {best_name_all} ({best_metrics_all['accuracy']:.4f})\")\n",
    "        print(f\"   Overall improvement: {best_metrics_all['accuracy'] - best_individual_acc_all:+.4f}\")\n",
    "        \n",
    "        if best_metrics_all['accuracy'] > best_individual_acc_all:\n",
    "            improvement_pct = (best_metrics_all['accuracy'] - best_individual_acc_all) * 100\n",
    "            print(f\"   âœ… Voting is BETTER by {improvement_pct:.2f}%!\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸  Individual models perform better on the full dataset\")\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ Note: Analysis performed on ALL {total_saved_samples} saved samples, not just current batch!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No saved samples found for comprehensive analysis\")\n",
    "        print(\"ðŸ”„ Falling back to current batch analysis...\")\n",
    "        \n",
    "        # Fallback to current batch only (your original voting code)\n",
    "        def ensemble_voting_strategies(hardware_preds, calibrated_preds):\n",
    "            \"\"\"Apply different ensemble voting strategies\"\"\"\n",
    "            \n",
    "            strategies = {}\n",
    "            \n",
    "            # Strategy 1: Simple majority voting (hardware + calibrated)\n",
    "            majority_sum = hardware_preds + calibrated_preds\n",
    "            strategies['simple_majority'] = (majority_sum >= 2).astype(int)\n",
    "            \n",
    "            # Strategy 2: Weighted voting \n",
    "            weighted = 0.5 * calibrated_preds + 0.5 * hardware_preds\n",
    "            strategies['weighted'] = (weighted > 0.5).astype(int)\n",
    "            \n",
    "            return strategies\n",
    "        \n",
    "        # Apply ensemble voting on current batch\n",
    "        print(\"ðŸ—³ï¸ Applying ensemble voting strategies...\")\n",
    "        ensemble_results = ensemble_voting_strategies(\n",
    "            hardware_predictions.astype(int), \n",
    "            calibrated_predictions\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Ensemble voting completed\")\n",
    "        print(f\"   Available strategies: {list(ensemble_results.keys())}\")\n",
    "        \n",
    "        # Evaluate ensemble strategies\n",
    "        y_batch_flat = y_batch.flatten()\n",
    "        ensemble_accuracies = {}\n",
    "        \n",
    "        print(\"\\nðŸ“Š Ensemble Strategy Accuracies:\")\n",
    "        for strategy_name, predictions in ensemble_results.items():\n",
    "            accuracy = accuracy_score(y_batch_flat, predictions.flatten())\n",
    "            ensemble_accuracies[strategy_name] = accuracy\n",
    "            print(f\"   {strategy_name:20s}: {accuracy:.4f}\")\n",
    "        \n",
    "        # Individual model accuracies for comparison\n",
    "        hardware_acc = accuracy_score(y_batch_flat, hardware_predictions.flatten())\n",
    "        calibrated_acc = accuracy_score(y_batch_flat, calibrated_predictions.flatten())\n",
    "        \n",
    "        print(\"\\nðŸ“ˆ Individual Model Accuracies:\")\n",
    "        print(f\"   Hardware (raw):      {hardware_acc:.4f}\")\n",
    "        print(f\"   Calibrated:          {calibrated_acc:.4f}\")\n",
    "        \n",
    "        # Find best strategy\n",
    "        best_strategy = max(ensemble_accuracies.items(), key=lambda x: x[1])\n",
    "        print(f\"\\nðŸ† Best ensemble strategy: {best_strategy[0]} with accuracy {best_strategy[1]:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No saved results file found!\")\n",
    "    print(\"ðŸ”„ Proceeding with current batch analysis only...\")\n",
    "    \n",
    "    # Fallback to current batch analysis (original code)\n",
    "    def ensemble_voting_strategies(hardware_preds, calibrated_preds):\n",
    "        \"\"\"Apply different ensemble voting strategies\"\"\"\n",
    "        \n",
    "        strategies = {}\n",
    "        \n",
    "        # Strategy 1: Simple majority voting (hardware + calibrated)\n",
    "        majority_sum = hardware_preds + calibrated_preds\n",
    "        strategies['simple_majority'] = (majority_sum >= 2).astype(int)\n",
    "        \n",
    "        # Strategy 2: Weighted voting \n",
    "        weighted = 0.5 * calibrated_preds + 0.5 * hardware_preds\n",
    "        strategies['weighted'] = (weighted > 0.5).astype(int)\n",
    "        \n",
    "        return strategies\n",
    "    \n",
    "    # Apply ensemble voting\n",
    "    print(\"ðŸ—³ï¸ Applying ensemble voting strategies...\")\n",
    "    ensemble_results = ensemble_voting_strategies(\n",
    "        hardware_predictions.astype(int), \n",
    "        calibrated_predictions\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Ensemble voting completed\")\n",
    "    print(f\"   Available strategies: {list(ensemble_results.keys())}\")\n",
    "    \n",
    "    # Evaluate ensemble strategies\n",
    "    y_batch_flat = y_batch.flatten()\n",
    "    ensemble_accuracies = {}\n",
    "    \n",
    "    print(\"\\nðŸ“Š Ensemble Strategy Accuracies:\")\n",
    "    for strategy_name, predictions in ensemble_results.items():\n",
    "        accuracy = accuracy_score(y_batch_flat, predictions.flatten())\n",
    "        ensemble_accuracies[strategy_name] = accuracy\n",
    "        print(f\"   {strategy_name:20s}: {accuracy:.4f}\")\n",
    "    \n",
    "    # Individual model accuracies for comparison\n",
    "    hardware_acc = accuracy_score(y_batch_flat, hardware_predictions.flatten())\n",
    "    calibrated_acc = accuracy_score(y_batch_flat, calibrated_predictions.flatten())\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Individual Model Accuracies:\")\n",
    "    print(f\"   Hardware (raw):      {hardware_acc:.4f}\")\n",
    "    print(f\"   Calibrated:          {calibrated_acc:.4f}\")\n",
    "    \n",
    "    # Find best strategy\n",
    "    best_strategy = max(ensemble_accuracies.items(), key=lambda x: x[1])\n",
    "    print(f\"\\nðŸ† Best ensemble strategy: {best_strategy[0]} with accuracy {best_strategy[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-saving",
   "metadata": {},
   "source": [
    "## Save Results and Job Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "save_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading existing results for continuation...\n",
      "   Existing samples: 80\n",
      "   Combined total samples: 90\n",
      "ðŸ’¾ Saving results to hardware_testing_results.pkl...\n",
      "âœ… Results saved successfully!\n",
      "   Results file: hardware_testing_results.pkl\n",
      "   Metadata file: job_metadata.json\n",
      "   Total samples processed: 90\n"
     ]
    }
   ],
   "source": [
    "# Fixed Save Results Cell - Replace the existing save_results cell with this\n",
    "\"\"\"\n",
    "This fixes the dict + dict error when adding new batches\n",
    "\"\"\"\n",
    "\n",
    "# Prepare comprehensive results\n",
    "results = {\n",
    "    'batch_info': {\n",
    "        'start_sample': START_SAMPLE,\n",
    "        'end_sample': END_SAMPLE,\n",
    "        'sample_indices': list(range(START_SAMPLE, END_SAMPLE)),\n",
    "        'locations': loc_batch.tolist(),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    },\n",
    "    'predictions': {\n",
    "        'hardware_raw': hardware_predictions.tolist(),\n",
    "        'hardware_calibrated': calibrated_predictions.tolist(),\n",
    "        'ensemble_strategies': {k: v.tolist() for k, v in ensemble_results.items()}\n",
    "    },\n",
    "    'probabilities': {\n",
    "        'hardware': hardware_probabilities.tolist(),\n",
    "    },\n",
    "    'ground_truth': y_batch.tolist(),\n",
    "    'accuracies': {\n",
    "        'hardware_raw': float(hardware_acc),\n",
    "        'hardware_calibrated': float(calibrated_acc),\n",
    "        'ensemble_strategies': ensemble_accuracies,\n",
    "        'best_strategy': {\n",
    "            'name': best_strategy[0],\n",
    "            'accuracy': float(best_strategy[1])\n",
    "        }\n",
    "    },\n",
    "    'calibration_info': {\n",
    "        'matrix_shape': calibration_matrix.shape,\n",
    "        'matrix_applied': True,\n",
    "        'average_change': float(np.mean(np.abs(hardware_predictions - calibrated_predictions)))\n",
    "    }\n",
    "}\n",
    "\n",
    "# Update job metadata\n",
    "job_metadata['results_summary'] = {\n",
    "    'samples_processed': len(X_batch),\n",
    "    'best_ensemble_accuracy': float(best_strategy[1]),\n",
    "    'hardware_accuracy': float(hardware_acc),\n",
    "    'improvement_over_hardware': float(best_strategy[1] - hardware_acc)\n",
    "}\n",
    "\n",
    "# Handle continuation: load existing results if they exist\n",
    "if os.path.exists(RESULTS_FILE) and START_SAMPLE > 0:\n",
    "    print(f\"ðŸ“‚ Loading existing results for continuation...\")\n",
    "    with open(RESULTS_FILE, 'rb') as f:\n",
    "        existing_results = pickle.load(f)\n",
    "    \n",
    "    # Get existing data\n",
    "    existing_batch_info = existing_results.get('batch_info', {})\n",
    "    existing_predictions = existing_results.get('predictions', {})\n",
    "    existing_probabilities = existing_results.get('probabilities', {})\n",
    "    existing_ground_truth = existing_results.get('ground_truth', [])\n",
    "    \n",
    "    print(f\"   Existing samples: {len(existing_batch_info.get('sample_indices', []))}\")\n",
    "    \n",
    "    # FIXED: Properly combine results without dict + dict error\n",
    "    combined_results = {\n",
    "        'batch_info': {\n",
    "            'start_sample': 0,  # Overall start\n",
    "            'end_sample': END_SAMPLE,  # Current end\n",
    "            'sample_indices': existing_batch_info.get('sample_indices', []) + results['batch_info']['sample_indices'],\n",
    "            'locations': existing_batch_info.get('locations', []) + results['batch_info']['locations'],\n",
    "            'timestamp': results['batch_info']['timestamp'],\n",
    "            'batches_processed': existing_batch_info.get('batches_processed', 1) + 1\n",
    "        },\n",
    "        'predictions': {},\n",
    "        'probabilities': {},\n",
    "        'ground_truth': existing_ground_truth + results['ground_truth'],\n",
    "        'accuracies': results['accuracies'],  # Keep latest batch accuracies\n",
    "        'calibration_info': results['calibration_info']\n",
    "    }\n",
    "    \n",
    "    # FIXED: Combine predictions properly\n",
    "    for key in ['hardware_raw', 'hardware_calibrated']:\n",
    "        if key in existing_predictions and key in results['predictions']:\n",
    "            combined_results['predictions'][key] = existing_predictions[key] + results['predictions'][key]\n",
    "        elif key in results['predictions']:\n",
    "            combined_results['predictions'][key] = results['predictions'][key]\n",
    "        elif key in existing_predictions:\n",
    "            combined_results['predictions'][key] = existing_predictions[key]\n",
    "    \n",
    "    # FIXED: Combine ensemble strategies properly\n",
    "    combined_ensemble = {}\n",
    "    existing_ensemble = existing_predictions.get('ensemble_strategies', {})\n",
    "    new_ensemble = results['predictions']['ensemble_strategies']\n",
    "    \n",
    "    # Get all strategy names\n",
    "    all_strategies = set(list(existing_ensemble.keys()) + list(new_ensemble.keys()))\n",
    "    \n",
    "    for strategy in all_strategies:\n",
    "        existing_strategy_data = existing_ensemble.get(strategy, [])\n",
    "        new_strategy_data = new_ensemble.get(strategy, [])\n",
    "        combined_ensemble[strategy] = existing_strategy_data + new_strategy_data\n",
    "    \n",
    "    combined_results['predictions']['ensemble_strategies'] = combined_ensemble\n",
    "    \n",
    "    # FIXED: Combine probabilities properly\n",
    "    for key in results['probabilities']:\n",
    "        if key in existing_probabilities:\n",
    "            combined_results['probabilities'][key] = existing_probabilities[key] + results['probabilities'][key]\n",
    "        else:\n",
    "            combined_results['probabilities'][key] = results['probabilities'][key]\n",
    "    \n",
    "    results = combined_results\n",
    "    print(f\"   Combined total samples: {len(results['batch_info']['sample_indices'])}\")\n",
    "\n",
    "# Save results\n",
    "print(f\"ðŸ’¾ Saving results to {RESULTS_FILE}...\")\n",
    "with open(RESULTS_FILE, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "# Save job metadata\n",
    "if os.path.exists(JOB_METADATA_FILE):\n",
    "    with open(JOB_METADATA_FILE, 'r') as f:\n",
    "        existing_metadata = json.load(f)\n",
    "    \n",
    "    if 'job_history' not in existing_metadata:\n",
    "        existing_metadata['job_history'] = []\n",
    "    existing_metadata['job_history'].append(job_metadata)\n",
    "    existing_metadata['latest_batch'] = job_metadata\n",
    "    \n",
    "    with open(JOB_METADATA_FILE, 'w') as f:\n",
    "        json.dump(existing_metadata, f, indent=2)\n",
    "else:\n",
    "    metadata_to_save = {\n",
    "        'job_history': [job_metadata],\n",
    "        'latest_batch': job_metadata\n",
    "    }\n",
    "    with open(JOB_METADATA_FILE, 'w') as f:\n",
    "        json.dump(metadata_to_save, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Results saved successfully!\")\n",
    "print(f\"   Results file: {RESULTS_FILE}\")\n",
    "print(f\"   Metadata file: {JOB_METADATA_FILE}\")\n",
    "print(f\"   Total samples processed: {len(results['batch_info']['sample_indices'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuation-guide",
   "metadata": {},
   "source": [
    "## Continuation Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "### ðŸ”„ Running Next Batch\n",
    "\n",
    "To process the next 10 samples:\n",
    "\n",
    "1. **Modify Configuration Cell:**\n",
    "   ```python\n",
    "   START_SAMPLE = 10  # For second batch\n",
    "   END_SAMPLE = 20    # For second batch\n",
    "   ```\n",
    "\n",
    "2. **Run All Cells Again** - The notebook will automatically:\n",
    "   - Load existing results\n",
    "   - Process new samples\n",
    "   - Append to existing results\n",
    "   - Update job metadata\n",
    "\n",
    "3. **For Subsequent Batches:**\n",
    "   - Third batch: START_SAMPLE=20, END_SAMPLE=30\n",
    "   - Fourth batch: START_SAMPLE=30, END_SAMPLE=40\n",
    "   - And so on...\n",
    "\n",
    "### ðŸ“Š Checking Progress\n",
    "Your results are automatically saved and can be analyzed at any time using the saved pickle and JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "summary_stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "           BATCH 9 COMPLETION SUMMARY\n",
      "============================================================\n",
      "Samples processed this batch: 10\n",
      "Total samples processed: 90\n",
      "Backend used: ibm_brisbane\n",
      "Best ensemble strategy: hardware_preference\n",
      "Best ensemble accuracy: 0.7528\n",
      "Hardware improvement: +0.0000\n",
      "\n",
      "ðŸŽ¯ Ready for next batch! Update START_SAMPLE and END_SAMPLE in config cell.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"           BATCH {START_SAMPLE//10 + 1} COMPLETION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Samples processed this batch: {END_SAMPLE - START_SAMPLE}\")\n",
    "print(f\"Total samples processed: {len(results['batch_info']['sample_indices'])}\")\n",
    "print(f\"Backend used: {BACKEND_NAME}\")\n",
    "print(f\"Best ensemble strategy: {best_strategy[0]}\")\n",
    "print(f\"Best ensemble accuracy: {best_strategy[1]:.4f}\")\n",
    "print(f\"Hardware improvement: {best_strategy[1] - hardware_acc:+.4f}\")\n",
    "print(\"\\nðŸŽ¯ Ready for next batch! Update START_SAMPLE and END_SAMPLE in config cell.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
